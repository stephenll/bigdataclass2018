[
["index.html", "Big Data with R - Exercise book", " Big Data with R - Exercise book Learn how to use R with Hive, SQL Server, Oracle and other scalable external data sources along with Big Data clusters in this two-day workshop. We will cover how to connect, retrieve schema information, upload data, and explore data outside of R. For databases, we will focus on the dplyr, DBI and odbc packages. These packages enable us to use the same dplyr verbs inside R but are translated and sent as SQL queries. For Big Data clusters, we will also learn how to use the sparklyr package to run models inside Spark and return the results to R. We will review recommendations for connection settings, security best practices and deployment options. Throughout the workshop, we will take advantage of the new data connections available with the RStudio IDE. "],
["access-a-database.html", "1 Access a database 1.1 Connect to a database 1.2 Explore the database using the RStudio IDE 1.3 List drivers and DSNs 1.4 Connect to a database using code 1.5 RStudio SQL Script 1.6 Connect to a database without a DSN 1.7 Secure credentials in a file 1.8 Environment variables 1.9 Use options()", " 1 Access a database 1.1 Connect to a database The simpliest way to connect to a database. More complex examples will be examined later in the class. Click on the Connections tab Click on the New Connection button Select Postgres Dev Click OK 1.2 Explore the database using the RStudio IDE Becoming familiar with the new interface for databases inside the RStudio IDE Expand the datawarehouse schema Expand the airport table Click on the table icon to the right of the airport table (Optional) Expand and explore the other tables Click on the disconnect icon to close the connection 1.3 List drivers and DSNs Learn how to use the odbc package to get DB info from your machine To get a list of drivers available in the server library(odbc) odbcListDrivers()[1:2] ## name attribute ## 1 AmazonRedshift Driver ## 2 Hive Driver ## 3 Impala Driver ## 4 Oracle Driver ## 5 PostgreSQL Driver ## 6 Salesforce Driver ## 7 SQLServer Driver ## 8 Teradata Driver Click on the ellipsis button located in the Files tab Type: /etc Locate and open the odbcinst.ini file To see a list of DSNs available in the server odbcListDataSources() ## name description ## 1 Postgres Dev PostgreSQL ## 2 Postgres Prod PostgreSQL Using the ellipsis button again, navigate to /etc/odbc.ini 1.4 Connect to a database using code Use the odbc package along with DBI to open a connection to a database Run the following code to connect library(DBI) con &lt;- dbConnect(odbc::odbc(), &quot;Postgres Dev&quot;) Use dbListTables() to retrieve a list of tables dbListTables(con) ## [1] &quot;airport&quot; &quot;carrier&quot; &quot;flight&quot; &quot;flightscore&quot; &quot;vflight&quot; Use dbGetQuery() to run a quick query odbc::dbGetQuery(con, &quot;SELECT * FROM datawarehouse.airport LIMIT 10&quot;) ## airport airportname city state country ## 1 ABE Lehigh Valley International Allentown PA USA ## 2 ABI Abilene Regional Abilene TX USA ## 3 ABQ Albuquerque International Albuquerque NM USA ## 4 ABY Southwest Georgia Regional Albany GA USA ## 5 ACK Nantucket Memorial Nantucket MA USA ## 6 ACT Waco Regional Waco TX USA ## 7 ACV Arcata Arcata/Eureka CA USA ## 8 ACY Atlantic City International Atlantic City NJ USA ## 9 ADK Adak Adak AK USA ## 10 ADQ Kodiak Kodiak AK USA ## lat long ## 1 40.65236 -75.44040 ## 2 32.41132 -99.68190 ## 3 35.04022 -106.60919 ## 4 31.53552 -84.19447 ## 5 41.25305 -70.06018 ## 6 31.61129 -97.23052 ## 7 40.97812 -124.10862 ## 8 39.45758 -74.57717 ## 9 51.87796 -176.64603 ## 10 57.74997 -152.49386 Use the SQL chunk SELECT * FROM datawarehouse.airport LIMIT 10 Table 1.1: Displaying records 1 - 10 airport airportname city state country lat long ABE Lehigh Valley International Allentown PA USA 40.65236 -75.44040 ABI Abilene Regional Abilene TX USA 32.41132 -99.68190 ABQ Albuquerque International Albuquerque NM USA 35.04022 -106.60919 ABY Southwest Georgia Regional Albany GA USA 31.53552 -84.19447 ACK Nantucket Memorial Nantucket MA USA 41.25305 -70.06018 ACT Waco Regional Waco TX USA 31.61129 -97.23052 ACV Arcata Arcata/Eureka CA USA 40.97812 -124.10862 ACY Atlantic City International Atlantic City NJ USA 39.45758 -74.57717 ADK Adak Adak AK USA 51.87796 -176.64603 ADQ Kodiak Kodiak AK USA 57.74997 -152.49386 Use the output.var option to load results to a variable SELECT * FROM datawarehouse.airport LIMIT 10 Test the variable sql_top10 ## airport airportname city state country ## 1 ABE Lehigh Valley International Allentown PA USA ## 2 ABI Abilene Regional Abilene TX USA ## 3 ABQ Albuquerque International Albuquerque NM USA ## 4 ABY Southwest Georgia Regional Albany GA USA ## 5 ACK Nantucket Memorial Nantucket MA USA ## 6 ACT Waco Regional Waco TX USA ## 7 ACV Arcata Arcata/Eureka CA USA ## 8 ACY Atlantic City International Atlantic City NJ USA ## 9 ADK Adak Adak AK USA ## 10 ADQ Kodiak Kodiak AK USA ## lat long ## 1 40.65236 -75.44040 ## 2 32.41132 -99.68190 ## 3 35.04022 -106.60919 ## 4 31.53552 -84.19447 ## 5 41.25305 -70.06018 ## 6 31.61129 -97.23052 ## 7 40.97812 -124.10862 ## 8 39.45758 -74.57717 ## 9 51.87796 -176.64603 ## 10 57.74997 -152.49386 Disconnect from the database using dbDisconnect() dbDisconnect(con) 1.5 RStudio SQL Script Try out the new SQL Script support in RStudio 1.2 Open the query-example.sql file Click the Preview button. It is located in the top-right area of the script In the script, change airport to carrier Click on Preview again 1.6 Connect to a database without a DSN A more complex way of connecting to a database, using best practices: http://db.rstudio.com/best-practices/managing-credentials/#prompt-for-credentials Use the following code to start a new connection that does not use the pre-defined DSN con &lt;- dbConnect( odbc::odbc(), Driver = &quot;PostgreSQL&quot;, Server = &quot;localhost&quot;, UID = rstudioapi::askForPassword(&quot;Database user&quot;), PWD = rstudioapi::askForPassword(&quot;Database password&quot;), Port = 5432, Database = &quot;postgres&quot; ) When prompted, type in rstudio_dev for the user, and dev_user as the password Disconnect from the database using dbDisconnect() dbDisconnect(con) ## Warning: Connection already closed. 1.7 Secure credentials in a file Credentials can be saved in a YAML file and then read using the config package: http://db.rstudio.com/best-practices/managing-credentials/#stored-in-a-file-with-config Open and explore the config.yml file available in your working directory Load the datawarehouse-dev values to a variable dw &lt;- config::get(&quot;datawarehouse-dev&quot;) Check that the variable loaded propery, by checking the driver value dw$driver ## [1] &quot;PostgreSQL&quot; Use info in the config.yml file to connect to the database con &lt;- dbConnect(odbc::odbc(), Driver = dw$driver, Server = dw$server, UID = dw$uid, PWD = dw$pwd, Port = dw$port, Database = dw$database ) Disconnect from the database using dbDisconnect() dbDisconnect(con) 1.8 Environment variables Use .Renviron file to store credentials Open and explore the .Renviron file available in your working directory Confirm that the environment variables are loaded by using Sys.getenv() Sys.getenv(&quot;uid&quot;) ## [1] &quot;rstudio_dev&quot; Pass the credentials using the environment variables con &lt;- dbConnect( odbc::odbc(), Driver = &quot;PostgreSQL&quot;, Server = &quot;localhost&quot;, UID = Sys.getenv(&quot;uid&quot;), PWD = Sys.getenv(&quot;pwd&quot;), Port = 5432, Database = &quot;postgres&quot; ) Disconnect from the database using dbDisconnect() dbDisconnect(con) 1.9 Use options() Set options() in a separate R script Open and explore the options.R script available in your working directory Source the options.R script source(&quot;options.R&quot;) Confirm that the environment variables are loaded by using Sys.getenv() getOption(&quot;database_userid&quot;) ## [1] &quot;rstudio_dev&quot; Pass the credentials using the environment variables con &lt;- dbConnect( odbc::odbc(), Driver = &quot;PostgreSQL&quot;, Server = &quot;localhost&quot;, UID = getOption(&quot;database_userid&quot;), PWD = getOption(&quot;database_password&quot;), Port = 5432, Database = &quot;postgres&quot; ) Disconnect from the database using dbDisconnect() dbDisconnect(con) ## Warning: Connection already closed. "],
["dplyr-basics.html", "2 dplyr Basics 2.1 Create a table variable 2.2 Under the hood 2.3 Un-translated R commands 2.4 Using bang-bang 2.5 knitr SQL engine 2.6 Basic aggregation", " 2 dplyr Basics 2.1 Create a table variable Basics to how to point a variable in R to a table or view inside the database Load the dplyr, DBI and dbplyr libraries library(dplyr) library(dbplyr) library(DBI) (Optional) Open a connection to the database if it’s currently closed con &lt;- dbConnect(odbc::odbc(), &quot;Postgres Dev&quot;) Use the tbl() and in_schema() functions to create a reference to a table tbl(con, in_schema(&quot;datawarehouse&quot;, &quot;airport&quot;)) ## # Source: table&lt;datawarehouse.airport&gt; [?? x 7] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## airport airportname city state country lat long ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ABE Lehigh Valley Internatio… Allentown PA USA 40.7 -75.4 ## 2 ABI Abilene Regional Abilene TX USA 32.4 -99.7 ## 3 ABQ Albuquerque International Albuquerque NM USA 35.0 -107. ## 4 ABY Southwest Georgia Region… Albany GA USA 31.5 -84.2 ## 5 ACK Nantucket Memorial Nantucket MA USA 41.3 -70.1 ## 6 ACT Waco Regional Waco TX USA 31.6 -97.2 ## 7 ACV Arcata Arcata/Eur… CA USA 41.0 -124. ## 8 ACY Atlantic City Internatio… Atlantic C… NJ USA 39.5 -74.6 ## 9 ADK Adak Adak AK USA 51.9 -177. ## 10 ADQ Kodiak Kodiak AK USA 57.7 -152. ## # … with more rows Load the reference, not the table data, into a variable airports &lt;- tbl(con, in_schema(&quot;datawarehouse&quot;, &quot;airport&quot;)) Call the variable to see preview the data in the table airports ## # Source: table&lt;datawarehouse.airport&gt; [?? x 7] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## airport airportname city state country lat long ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ABE Lehigh Valley Internatio… Allentown PA USA 40.7 -75.4 ## 2 ABI Abilene Regional Abilene TX USA 32.4 -99.7 ## 3 ABQ Albuquerque International Albuquerque NM USA 35.0 -107. ## 4 ABY Southwest Georgia Region… Albany GA USA 31.5 -84.2 ## 5 ACK Nantucket Memorial Nantucket MA USA 41.3 -70.1 ## 6 ACT Waco Regional Waco TX USA 31.6 -97.2 ## 7 ACV Arcata Arcata/Eur… CA USA 41.0 -124. ## 8 ACY Atlantic City Internatio… Atlantic C… NJ USA 39.5 -74.6 ## 9 ADK Adak Adak AK USA 51.9 -177. ## 10 ADQ Kodiak Kodiak AK USA 57.7 -152. ## # … with more rows Set up the pointers to the other of the tables flights &lt;- tbl(con, in_schema(&quot;datawarehouse&quot;, &quot;vflight&quot;)) carriers &lt;- tbl(con, in_schema(&quot;datawarehouse&quot;, &quot;carrier&quot;)) 2.2 Under the hood Use show_query() to preview the SQL statement that will be sent to the database SQL statement that actually runs when we ran airports as a command show_query(airports) ## &lt;SQL&gt; ## SELECT * ## FROM datawarehouse.airport Easily view the resulting query by adding show_query() in another piped command airports %&gt;% show_query() ## &lt;SQL&gt; ## SELECT * ## FROM datawarehouse.airport Insert head() in between the two statements to see how the SQL changes airports %&gt;% head() %&gt;% show_query() ## &lt;SQL&gt; ## SELECT * ## FROM datawarehouse.airport ## LIMIT 6 Use sql_render() and simulate_mssql() to see how the SQL statement changes from vendor to vendor airports %&gt;% head() %&gt;% sql_render(con = simulate_mssql()) ## &lt;SQL&gt; SELECT TOP 6 * ## FROM datawarehouse.airport Use explain() to explore the query plan airports %&gt;% head() %&gt;% explain() ## &lt;SQL&gt; ## SELECT * ## FROM datawarehouse.airport ## LIMIT 6 ## ## &lt;PLAN&gt; ## Limit (cost=0.00..0.14 rows=6 width=56) ## -&gt; Seq Scan on airport (cost=0.00..7.05 rows=305 width=56) 2.3 Un-translated R commands Review of how dbplyr handles R commands that have not been translated into a like-SQL command Preview how Sys.time() is translated airports %&gt;% mutate(today = Sys.time()) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT &quot;airport&quot;, &quot;airportname&quot;, &quot;city&quot;, &quot;state&quot;, &quot;country&quot;, &quot;lat&quot;, &quot;long&quot;, SYS.TIME() AS &quot;today&quot; ## FROM datawarehouse.airport Use PostgreSQL’s native commands, in this case now() airports %&gt;% mutate(today = now()) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT &quot;airport&quot;, &quot;airportname&quot;, &quot;city&quot;, &quot;state&quot;, &quot;country&quot;, &quot;lat&quot;, &quot;long&quot;, NOW() AS &quot;today&quot; ## FROM datawarehouse.airport Run the dplyr code to confirm it works airports %&gt;% mutate(today = now()) %&gt;% select(today) %&gt;% head() ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## today ## &lt;dttm&gt; ## 1 2019-01-11 03:43:50 ## 2 2019-01-11 03:43:50 ## 3 2019-01-11 03:43:50 ## 4 2019-01-11 03:43:50 ## 5 2019-01-11 03:43:50 ## 6 2019-01-11 03:43:50 2.4 Using bang-bang Intro on passing unevaluated code to a dplyr verb Preview how Sys.time() is translated airports %&gt;% mutate(today = Sys.time()) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT &quot;airport&quot;, &quot;airportname&quot;, &quot;city&quot;, &quot;state&quot;, &quot;country&quot;, &quot;lat&quot;, &quot;long&quot;, SYS.TIME() AS &quot;today&quot; ## FROM datawarehouse.airport Preview how Sys.time() is translated when prefixing !! airports %&gt;% mutate(today = !!Sys.time()) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT &quot;airport&quot;, &quot;airportname&quot;, &quot;city&quot;, &quot;state&quot;, &quot;country&quot;, &quot;lat&quot;, &quot;long&quot;, &#39;2019-01-11T03:43:50Z&#39; AS &quot;today&quot; ## FROM datawarehouse.airport Preview how Sys.time() is translated when prefixing !! airports %&gt;% mutate(today = !!Sys.time()) %&gt;% select(today) %&gt;% head() ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## today ## &lt;chr&gt; ## 1 2019-01-11T03:43:50Z ## 2 2019-01-11T03:43:50Z ## 3 2019-01-11T03:43:50Z ## 4 2019-01-11T03:43:50Z ## 5 2019-01-11T03:43:50Z ## 6 2019-01-11T03:43:50Z 2.5 knitr SQL engine Copy the result of the latest show_query() exercise airports %&gt;% mutate(today = !!Sys.time()) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT &quot;airport&quot;, &quot;airportname&quot;, &quot;city&quot;, &quot;state&quot;, &quot;country&quot;, &quot;lat&quot;, &quot;long&quot;, &#39;2019-01-11T03:43:50Z&#39; AS &quot;today&quot; ## FROM datawarehouse.airport Paste the result in this SQL chunk SELECT &quot;airport&quot;, &quot;airportname&quot;, &quot;city&quot;, &quot;state&quot;, &quot;country&quot;, &quot;lat&quot;, &quot;long&quot;, &#39;2018-01-26T14:50:10Z&#39; AS &quot;today&quot; FROM datawarehouse.airport Table 2.1: Displaying records 1 - 10 airport airportname city state country lat long today ABE Lehigh Valley International Allentown PA USA 40.65236 -75.44040 2018-01-26T14:50:10Z ABI Abilene Regional Abilene TX USA 32.41132 -99.68190 2018-01-26T14:50:10Z ABQ Albuquerque International Albuquerque NM USA 35.04022 -106.60919 2018-01-26T14:50:10Z ABY Southwest Georgia Regional Albany GA USA 31.53552 -84.19447 2018-01-26T14:50:10Z ACK Nantucket Memorial Nantucket MA USA 41.25305 -70.06018 2018-01-26T14:50:10Z ACT Waco Regional Waco TX USA 31.61129 -97.23052 2018-01-26T14:50:10Z ACV Arcata Arcata/Eureka CA USA 40.97812 -124.10862 2018-01-26T14:50:10Z ACY Atlantic City International Atlantic City NJ USA 39.45758 -74.57717 2018-01-26T14:50:10Z ADK Adak Adak AK USA 51.87796 -176.64603 2018-01-26T14:50:10Z ADQ Kodiak Kodiak AK USA 57.74997 -152.49386 2018-01-26T14:50:10Z 2.6 Basic aggregation A couple of dplyr commands that run in-database How many records are in the airport table? tbl(con, in_schema(&quot;datawarehouse&quot;, &quot;airport&quot;)) %&gt;% tally() ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## n ## &lt;S3: integer64&gt; ## 1 305 What is the average character length of the airport codes? How many characters is the longest and the shortest airport name? airports %&gt;% summarise( avg_airport_length = mean(str_length(airport), na.rm = TRUE), max_airport_name = max(str_length(airportname), na.rm = TRUE), min_airport_name = min(str_length(airportname), na.rm = TRUE), total_records = n() ) ## # Source: lazy query [?? x 4] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## avg_airport_length max_airport_name min_airport_name total_records ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;S3: integer64&gt; ## 1 3 40 3 305 How many records are in the carrier table? carriers %&gt;% tally() ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## n ## &lt;S3: integer64&gt; ## 1 20 How many characters is the longest carriername? carriers %&gt;% summarise(x = max(str_length(carriername), na.rm = TRUE)) ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## x ## &lt;int&gt; ## 1 83 What is the SQL statement sent in exercise 4? carriers %&gt;% summarise(x = max(str_length(carriername), na.rm = TRUE)) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT MAX(LENGTH(&quot;carriername&quot;)) AS &quot;x&quot; ## FROM datawarehouse.carrier "],
["data-transformation.html", "3 Data transformation 3.1 Group and sort records 3.2 Answering questions with dplyr 3.3 Aggregate mulitple columns 3.4 Data correlation 3.5 View record level data 3.6 Case statements 3.7 Data enrichment", " 3 Data transformation 3.1 Group and sort records Learn how to use group_by() and arrange() to better understand aggregated data How many flights are there per month? flights %&gt;% group_by(month) %&gt;% tally() ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## month n ## &lt;dbl&gt; &lt;S3: integer64&gt; ## 1 1 605765 ## 2 2 569236 ## 3 3 616090 ## 4 4 598126 ## 5 5 606293 ## 6 6 608665 ## 7 7 627931 ## 8 8 612279 ## 9 9 540908 ## 10 10 556205 ## # … with more rows Order the results by the month number by using arrange() flights %&gt;% group_by(month) %&gt;% tally() %&gt;% arrange(month) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Ordered by: month ## month n ## &lt;dbl&gt; &lt;S3: integer64&gt; ## 1 1 605765 ## 2 2 569236 ## 3 3 616090 ## 4 4 598126 ## 5 5 606293 ## 6 6 608665 ## 7 7 627931 ## 8 8 612279 ## 9 9 540908 ## 10 10 556205 ## # … with more rows Order the results by the number of flights, starting with the month with most flights by using desc() inside the arrange() command flights %&gt;% group_by(month) %&gt;% tally() %&gt;% arrange(desc(n)) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Ordered by: desc(n) ## month n ## &lt;dbl&gt; &lt;S3: integer64&gt; ## 1 7 627931 ## 2 3 616090 ## 3 8 612279 ## 4 6 608665 ## 5 5 606293 ## 6 1 605765 ## 7 4 598126 ## 8 2 569236 ## 9 10 556205 ## 10 12 544958 ## # … with more rows 3.2 Answering questions with dplyr Quick review of how to translate questions into dplyr code Which are the top 4 months with the most flight activity? flights %&gt;% group_by(month) %&gt;% tally() %&gt;% arrange(desc(n)) %&gt;% head(4) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Ordered by: desc(n) ## month n ## &lt;dbl&gt; &lt;S3: integer64&gt; ## 1 7 627931 ## 2 3 616090 ## 3 8 612279 ## 4 6 608665 What were the top 5 calendar days with most flight activity? flights %&gt;% group_by(month, dayofmonth) %&gt;% tally() %&gt;% arrange(desc(n)) %&gt;% head(5) ## # Source: lazy query [?? x 3] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Groups: month ## # Ordered by: desc(n) ## month dayofmonth n ## &lt;dbl&gt; &lt;dbl&gt; &lt;S3: integer64&gt; ## 1 7 18 21128 ## 2 7 11 21125 ## 3 7 25 21102 ## 4 7 10 21058 ## 5 7 17 21055 Which are the top 5 carriers (airlines) with the most flights? flights %&gt;% group_by(carriername) %&gt;% tally() %&gt;% arrange(desc(n)) %&gt;% head(5) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Ordered by: desc(n) ## carriername n ## &lt;chr&gt; &lt;S3: intege&gt; ## 1 Southwest Airlines Co. 1201754 ## 2 American Airlines Inc. 604885 ## 3 Skywest Airlines Inc. 567159 ## 4 American Eagle Airlines Inc. 490693 ## 5 US Airways Inc. (Merged with America West 9/05. Reporting f… 453589 Figure the percent ratio of flights per month flights %&gt;% group_by(month) %&gt;% tally() %&gt;% arrange(desc(n)) %&gt;% mutate(percent = n/sum(n, na.rm = TRUE)) ## # Source: lazy query [?? x 3] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Ordered by: desc(n) ## month n percent ## &lt;dbl&gt; &lt;S3: integer64&gt; &lt;dbl&gt; ## 1 7 627931 0.0896 ## 2 3 616090 0.0879 ## 3 8 612279 0.0873 ## 4 6 608665 0.0868 ## 5 5 606293 0.0865 ## 6 1 605765 0.0864 ## 7 4 598126 0.0853 ## 8 2 569236 0.0812 ## 9 10 556205 0.0793 ## 10 12 544958 0.0777 ## # … with more rows Figure the percent ratio of flights per carrier flights %&gt;% group_by(carriername) %&gt;% tally() %&gt;% arrange(desc(n)) %&gt;% mutate(percent = n/sum(n, na.rm = TRUE)) ## # Source: lazy query [?? x 3] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Ordered by: desc(n) ## carriername n percent ## &lt;chr&gt; &lt;S3: integ&gt; &lt;dbl&gt; ## 1 Southwest Airlines Co. 1201754 0.171 ## 2 American Airlines Inc. 604885 0.0863 ## 3 Skywest Airlines Inc. 567159 0.0809 ## 4 American Eagle Airlines Inc. 490693 0.0700 ## 5 US Airways Inc. (Merged with America West 9/05. Rep… 453589 0.0647 ## 6 Delta Air Lines Inc. 451931 0.0645 ## 7 United Air Lines Inc. 449515 0.0641 ## 8 Expressjet Airlines Inc. 374510 0.0534 ## 9 Northwest Airlines Inc. 347652 0.0496 ## 10 Continental Air Lines Inc. 298455 0.0426 ## # … with more rows 3.3 Aggregate mulitple columns Practice using summarise _ functions Use summarise_all() to send the same function to all fields flights %&gt;% select(depdelay, arrdelay) %&gt;% summarise_all(mean, na.rm = TRUE) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## depdelay arrdelay ## &lt;dbl&gt; &lt;dbl&gt; ## 1 9.97 8.17 Use summarise_at() to pre-select the fields that will receive the function flights %&gt;% summarise_at(c(&quot;depdelay&quot;, &quot;arrdelay&quot;), mean, na.rm = TRUE) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## depdelay arrdelay ## &lt;dbl&gt; &lt;dbl&gt; ## 1 9.97 8.17 Use summarise_if() to summarize only if the field meets a criterion flights %&gt;% summarise_if(is.numeric, mean, na.rm = TRUE) ## Applying predicate on the first 100 rows ## # Source: lazy query [?? x 30] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## carrierdelay originlat originlong destlat destlong flightid year month ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 15.8 36.9 -95.1 36.9 -95.1 3504864. 2008 6.38 ## # … with 22 more variables: dayofmonth &lt;dbl&gt;, dayofweek &lt;dbl&gt;, ## # deptime &lt;dbl&gt;, crsdeptime &lt;dbl&gt;, arrtime &lt;dbl&gt;, crsarrtime &lt;dbl&gt;, ## # flightnum &lt;dbl&gt;, actualelapsedtime &lt;dbl&gt;, crselapsedtime &lt;dbl&gt;, ## # airtime &lt;dbl&gt;, arrdelay &lt;dbl&gt;, depdelay &lt;dbl&gt;, distance &lt;dbl&gt;, ## # taxiin &lt;dbl&gt;, taxiout &lt;dbl&gt;, cancelled &lt;dbl&gt;, diverted &lt;dbl&gt;, ## # weatherdelay &lt;dbl&gt;, nasdelay &lt;dbl&gt;, securitydelay &lt;dbl&gt;, ## # lateaircraftdelay &lt;dbl&gt;, score &lt;dbl&gt; Combine with group_by() to create more complex results flights %&gt;% select(month, depdelay, arrdelay) %&gt;% group_by(month) %&gt;% summarise_all(mean, na.rm = TRUE) ## # Source: lazy query [?? x 3] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## month depdelay arrdelay ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 11.5 10.2 ## 2 2 13.7 13.1 ## 3 3 12.5 11.2 ## 4 4 8.20 6.81 ## 5 5 7.64 5.98 ## 6 6 13.6 13.3 ## 7 7 11.8 9.98 ## 8 8 9.61 6.91 ## 9 9 3.96 0.698 ## 10 10 3.80 0.415 ## # … with more rows 3.4 Data correlation Calculate correlation values in database Correlate select numeric columns from the flights table library(corrr) flights_cor &lt;- flights %&gt;% select(contains(&quot;delay&quot;)) %&gt;% correlate(use = &quot;complete.obs&quot;) ## ## Correlation method: &#39;pearson&#39; ## Missing treated using: &#39;complete.obs&#39; Explore the flights_cor data flights_cor %&gt;% rearrange() %&gt;% shave() %&gt;% fashion() ## rowname depdelay arrdelay carrierdelay lateaircraftdelay ## 1 depdelay ## 2 arrdelay .93 ## 3 carrierdelay .55 .52 ## 4 lateaircraftdelay .55 .50 -.13 ## 5 nasdelay .15 .35 -.14 -.15 ## 6 weatherdelay .25 .27 -.05 -.04 ## 7 securitydelay .00 .00 -.01 -.01 ## nasdelay weatherdelay securitydelay ## 1 ## 2 ## 3 ## 4 ## 5 ## 6 -.01 ## 7 -.01 -.01 3.5 View record level data Important tips to record preview data How many flights in July 18th were one or more hours late? flights %&gt;% filter( depdelay &gt;= 60, month == 7, dayofmonth == 18 ) %&gt;% tally() ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## n ## &lt;S3: integer64&gt; ## 1 1239 Use filter() to retrieve only the needed data, and head() to limit the preview even further. flights %&gt;% filter( depdelay &gt;= 60, month == 7, dayofmonth == 18 ) %&gt;% head(100) ## # Source: lazy query [?? x 44] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## uniquecarrier carrierdelay carriername origin originname origincity ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 WN 0 Southwest … ABQ Albuquerq… Albuquerq… ## 2 WN 42 Southwest … ABQ Albuquerq… Albuquerq… ## 3 WN 122 Southwest … ABQ Albuquerq… Albuquerq… ## 4 WN 0 Southwest … ABQ Albuquerq… Albuquerq… ## 5 WN 71 Southwest … ABQ Albuquerq… Albuquerq… ## 6 WN 14 Southwest … ABQ Albuquerq… Albuquerq… ## 7 WN 84 Southwest … AUS Austin-Be… Austin ## 8 WN 56 Southwest … AUS Austin-Be… Austin ## 9 WN 0 Southwest … BNA Nashville… Nashville ## 10 WN 32 Southwest … BNA Nashville… Nashville ## # … with more rows, and 38 more variables: originstate &lt;chr&gt;, ## # origincountry &lt;chr&gt;, originlat &lt;dbl&gt;, originlong &lt;dbl&gt;, dest &lt;chr&gt;, ## # destname &lt;chr&gt;, destcity &lt;chr&gt;, deststate &lt;chr&gt;, destcountry &lt;chr&gt;, ## # destlat &lt;dbl&gt;, destlong &lt;dbl&gt;, flightid &lt;int&gt;, year &lt;dbl&gt;, ## # month &lt;dbl&gt;, dayofmonth &lt;dbl&gt;, dayofweek &lt;dbl&gt;, deptime &lt;dbl&gt;, ## # crsdeptime &lt;dbl&gt;, arrtime &lt;dbl&gt;, crsarrtime &lt;dbl&gt;, flightnum &lt;dbl&gt;, ## # tailnum &lt;chr&gt;, actualelapsedtime &lt;dbl&gt;, crselapsedtime &lt;dbl&gt;, ## # airtime &lt;dbl&gt;, arrdelay &lt;dbl&gt;, depdelay &lt;dbl&gt;, distance &lt;dbl&gt;, ## # taxiin &lt;dbl&gt;, taxiout &lt;dbl&gt;, cancelled &lt;dbl&gt;, cancellationcode &lt;chr&gt;, ## # diverted &lt;dbl&gt;, weatherdelay &lt;dbl&gt;, nasdelay &lt;dbl&gt;, ## # securitydelay &lt;dbl&gt;, lateaircraftdelay &lt;dbl&gt;, score &lt;int&gt; Use collect() and View() to preview the data in the IDE. Make sure to always limit the number of returned rows. https://github.com/tidyverse/tibble/issues/373 flights %&gt;% filter( depdelay &gt;= 60, month == 7, dayofmonth == 18 ) %&gt;% collect() %&gt;% head(100) %&gt;% View(&quot;my_preview&quot;) 3.6 Case statements See how to use the flexibility of case statements for special cases Use case_when() to bucket each month into one of four seasons flights %&gt;% mutate( season = case_when( month &gt;= 3 &amp;&amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp;&amp; month &lt;= 8 ~ &quot;Summer&quot;, month &gt;= 9 &amp;&amp; month &lt;= 11 ~ &quot;Fall&quot;, TRUE ~ &quot;Winter&quot; ) ) %&gt;% group_by(season) %&gt;% tally() ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## season n ## &lt;chr&gt; &lt;S3: integer64&gt; ## 1 Fall 1620385 ## 2 Spring 1820509 ## 3 Summer 1848875 ## 4 Winter 1719959 Add a specific case for “Winter” flights %&gt;% mutate( season = case_when( month &gt;= 3 &amp;&amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp;&amp; month &lt;= 8 ~ &quot;Summer&quot;, month &gt;= 9 &amp;&amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot; ) ) %&gt;% group_by(season) %&gt;% tally() ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## season n ## &lt;chr&gt; &lt;S3: integer64&gt; ## 1 Fall 1620385 ## 2 Spring 1820509 ## 3 Summer 1848875 ## 4 Winter 1719959 Append an entry for Monday at the end of the case statement flights %&gt;% mutate( season = case_when( month &gt;= 3 &amp;&amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp;&amp; month &lt;= 8 ~ &quot;Summer&quot;, month &gt;= 9 &amp;&amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot;, dayofweek == 1 ~ &quot;Monday&quot; ) ) %&gt;% group_by(season) %&gt;% tally() ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## season n ## &lt;chr&gt; &lt;S3: integer64&gt; ## 1 Fall 1620385 ## 2 Spring 1820509 ## 3 Summer 1848875 ## 4 Winter 1719959 Move the “Monday” entry to the top of the case statement flights %&gt;% mutate( season = case_when( dayofweek == 1 ~ &quot;Monday&quot;, month &gt;= 3 &amp;&amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp;&amp; month &lt;= 8 ~ &quot;Summer&quot;, month &gt;= 9 &amp;&amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot; ) ) %&gt;% group_by(season) %&gt;% tally() ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## season n ## &lt;chr&gt; &lt;S3: integer64&gt; ## 1 Fall 1376740 ## 2 Monday 1036201 ## 3 Spring 1554210 ## 4 Summer 1577629 ## 5 Winter 1464948 3.7 Data enrichment Upload a small dataset in order to combine it with the datawarehouse data Load the planes data into memory planes &lt;- nycflights13::planes Using DBI, copy the planes data to the datawarehouse as a temporary table, and load it to a variable dbWriteTable(con, &quot;planes&quot;, planes, temporary = TRUE) tbl_planes &lt;- tbl(con, &quot;planes&quot;) Create a “lazy” variable that joins the flights table to the new temp table combined &lt;- flights %&gt;% left_join(tbl_planes, by = &quot;tailnum&quot;) View a sample of flights of planes with more than 100 seats combined %&gt;% filter(seats &gt; 100) %&gt;% head() ## # Source: lazy query [?? x 52] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## uniquecarrier carrierdelay carriername origin originname origincity ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 WN NA Southwest … ABQ Albuquerq… Albuquerq… ## 2 WN NA Southwest … ABQ Albuquerq… Albuquerq… ## 3 WN 14 Southwest … ABQ Albuquerq… Albuquerq… ## 4 WN NA Southwest … ABQ Albuquerq… Albuquerq… ## 5 WN NA Southwest … ABQ Albuquerq… Albuquerq… ## 6 WN NA Southwest … ABQ Albuquerq… Albuquerq… ## # … with 46 more variables: originstate &lt;chr&gt;, origincountry &lt;chr&gt;, ## # originlat &lt;dbl&gt;, originlong &lt;dbl&gt;, dest &lt;chr&gt;, destname &lt;chr&gt;, ## # destcity &lt;chr&gt;, deststate &lt;chr&gt;, destcountry &lt;chr&gt;, destlat &lt;dbl&gt;, ## # destlong &lt;dbl&gt;, flightid &lt;int&gt;, year.x &lt;dbl&gt;, month &lt;dbl&gt;, ## # dayofmonth &lt;dbl&gt;, dayofweek &lt;dbl&gt;, deptime &lt;dbl&gt;, crsdeptime &lt;dbl&gt;, ## # arrtime &lt;dbl&gt;, crsarrtime &lt;dbl&gt;, flightnum &lt;dbl&gt;, tailnum &lt;chr&gt;, ## # actualelapsedtime &lt;dbl&gt;, crselapsedtime &lt;dbl&gt;, airtime &lt;dbl&gt;, ## # arrdelay &lt;dbl&gt;, depdelay &lt;dbl&gt;, distance &lt;dbl&gt;, taxiin &lt;dbl&gt;, ## # taxiout &lt;dbl&gt;, cancelled &lt;dbl&gt;, cancellationcode &lt;chr&gt;, ## # diverted &lt;dbl&gt;, weatherdelay &lt;dbl&gt;, nasdelay &lt;dbl&gt;, ## # securitydelay &lt;dbl&gt;, lateaircraftdelay &lt;dbl&gt;, score &lt;int&gt;, ## # year.y &lt;int&gt;, type &lt;chr&gt;, manufacturer &lt;chr&gt;, model &lt;chr&gt;, ## # engines &lt;int&gt;, seats &lt;int&gt;, speed &lt;int&gt;, engine &lt;chr&gt; How many flights are from McDonnel Douglas planes combined %&gt;% filter(manufacturer == &quot;MCDONNELL DOUGLAS&quot;) %&gt;% tally() ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## n ## &lt;S3: integer64&gt; ## 1 137250 See how many flights each plane McDonnel Douglas had combined %&gt;% filter(manufacturer == &quot;MCDONNELL DOUGLAS&quot;) %&gt;% group_by(tailnum) %&gt;% tally() ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## tailnum n ## &lt;chr&gt; &lt;S3: integer64&gt; ## 1 N424AA 1479 ## 2 N426AA 1413 ## 3 N433AA 1153 ## 4 N434AA 1208 ## 5 N435AA 1185 ## 6 N436AA 1155 ## 7 N437AA 1233 ## 8 N438AA 1243 ## 9 N439AA 1251 ## 10 N454AA 1432 ## # … with more rows Get the total number of planes, and the average, minimum &amp; maximum number of flights for the manufacturer combined %&gt;% filter(manufacturer == &quot;MCDONNELL DOUGLAS&quot;) %&gt;% group_by(tailnum) %&gt;% tally() %&gt;% summarise(planes = n(), avg_flights = mean(n, na.rm = TRUE), max_flights = max(n, na.rm = TRUE), min_flights = min(n, na.rm = TRUE)) ## # Source: lazy query [?? x 4] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## planes avg_flights max_flights min_flights ## &lt;S3: integer64&gt; &lt;dbl&gt; &lt;S3: integer64&gt; &lt;S3: integer64&gt; ## 1 102 1346. 1850 1068 Use explain() to see the query plan combined %&gt;% filter(manufacturer == &quot;MCDONNELL DOUGLAS&quot;) %&gt;% group_by(tailnum) %&gt;% tally() %&gt;% summarise(planes = n(), avg_flights = mean(n, na.rm = TRUE), max_flights = max(n, na.rm = TRUE), min_flights = min(n, na.rm = TRUE)) %&gt;% explain() ## &lt;SQL&gt; ## SELECT COUNT(*) AS &quot;planes&quot;, AVG(&quot;n&quot;) AS &quot;avg_flights&quot;, MAX(&quot;n&quot;) AS &quot;max_flights&quot;, MIN(&quot;n&quot;) AS &quot;min_flights&quot; ## FROM (SELECT &quot;tailnum&quot;, COUNT(*) AS &quot;n&quot; ## FROM (SELECT * ## FROM (SELECT &quot;TBL_LEFT&quot;.&quot;uniquecarrier&quot; AS &quot;uniquecarrier&quot;, &quot;TBL_LEFT&quot;.&quot;carrierdelay&quot; AS &quot;carrierdelay&quot;, &quot;TBL_LEFT&quot;.&quot;carriername&quot; AS &quot;carriername&quot;, &quot;TBL_LEFT&quot;.&quot;origin&quot; AS &quot;origin&quot;, &quot;TBL_LEFT&quot;.&quot;originname&quot; AS &quot;originname&quot;, &quot;TBL_LEFT&quot;.&quot;origincity&quot; AS &quot;origincity&quot;, &quot;TBL_LEFT&quot;.&quot;originstate&quot; AS &quot;originstate&quot;, &quot;TBL_LEFT&quot;.&quot;origincountry&quot; AS &quot;origincountry&quot;, &quot;TBL_LEFT&quot;.&quot;originlat&quot; AS &quot;originlat&quot;, &quot;TBL_LEFT&quot;.&quot;originlong&quot; AS &quot;originlong&quot;, &quot;TBL_LEFT&quot;.&quot;dest&quot; AS &quot;dest&quot;, &quot;TBL_LEFT&quot;.&quot;destname&quot; AS &quot;destname&quot;, &quot;TBL_LEFT&quot;.&quot;destcity&quot; AS &quot;destcity&quot;, &quot;TBL_LEFT&quot;.&quot;deststate&quot; AS &quot;deststate&quot;, &quot;TBL_LEFT&quot;.&quot;destcountry&quot; AS &quot;destcountry&quot;, &quot;TBL_LEFT&quot;.&quot;destlat&quot; AS &quot;destlat&quot;, &quot;TBL_LEFT&quot;.&quot;destlong&quot; AS &quot;destlong&quot;, &quot;TBL_LEFT&quot;.&quot;flightid&quot; AS &quot;flightid&quot;, &quot;TBL_LEFT&quot;.&quot;year&quot; AS &quot;year.x&quot;, &quot;TBL_LEFT&quot;.&quot;month&quot; AS &quot;month&quot;, &quot;TBL_LEFT&quot;.&quot;dayofmonth&quot; AS &quot;dayofmonth&quot;, &quot;TBL_LEFT&quot;.&quot;dayofweek&quot; AS &quot;dayofweek&quot;, &quot;TBL_LEFT&quot;.&quot;deptime&quot; AS &quot;deptime&quot;, &quot;TBL_LEFT&quot;.&quot;crsdeptime&quot; AS &quot;crsdeptime&quot;, &quot;TBL_LEFT&quot;.&quot;arrtime&quot; AS &quot;arrtime&quot;, &quot;TBL_LEFT&quot;.&quot;crsarrtime&quot; AS &quot;crsarrtime&quot;, &quot;TBL_LEFT&quot;.&quot;flightnum&quot; AS &quot;flightnum&quot;, &quot;TBL_LEFT&quot;.&quot;tailnum&quot; AS &quot;tailnum&quot;, &quot;TBL_LEFT&quot;.&quot;actualelapsedtime&quot; AS &quot;actualelapsedtime&quot;, &quot;TBL_LEFT&quot;.&quot;crselapsedtime&quot; AS &quot;crselapsedtime&quot;, &quot;TBL_LEFT&quot;.&quot;airtime&quot; AS &quot;airtime&quot;, &quot;TBL_LEFT&quot;.&quot;arrdelay&quot; AS &quot;arrdelay&quot;, &quot;TBL_LEFT&quot;.&quot;depdelay&quot; AS &quot;depdelay&quot;, &quot;TBL_LEFT&quot;.&quot;distance&quot; AS &quot;distance&quot;, &quot;TBL_LEFT&quot;.&quot;taxiin&quot; AS &quot;taxiin&quot;, &quot;TBL_LEFT&quot;.&quot;taxiout&quot; AS &quot;taxiout&quot;, &quot;TBL_LEFT&quot;.&quot;cancelled&quot; AS &quot;cancelled&quot;, &quot;TBL_LEFT&quot;.&quot;cancellationcode&quot; AS &quot;cancellationcode&quot;, &quot;TBL_LEFT&quot;.&quot;diverted&quot; AS &quot;diverted&quot;, &quot;TBL_LEFT&quot;.&quot;weatherdelay&quot; AS &quot;weatherdelay&quot;, &quot;TBL_LEFT&quot;.&quot;nasdelay&quot; AS &quot;nasdelay&quot;, &quot;TBL_LEFT&quot;.&quot;securitydelay&quot; AS &quot;securitydelay&quot;, &quot;TBL_LEFT&quot;.&quot;lateaircraftdelay&quot; AS &quot;lateaircraftdelay&quot;, &quot;TBL_LEFT&quot;.&quot;score&quot; AS &quot;score&quot;, &quot;TBL_RIGHT&quot;.&quot;year&quot; AS &quot;year.y&quot;, &quot;TBL_RIGHT&quot;.&quot;type&quot; AS &quot;type&quot;, &quot;TBL_RIGHT&quot;.&quot;manufacturer&quot; AS &quot;manufacturer&quot;, &quot;TBL_RIGHT&quot;.&quot;model&quot; AS &quot;model&quot;, &quot;TBL_RIGHT&quot;.&quot;engines&quot; AS &quot;engines&quot;, &quot;TBL_RIGHT&quot;.&quot;seats&quot; AS &quot;seats&quot;, &quot;TBL_RIGHT&quot;.&quot;speed&quot; AS &quot;speed&quot;, &quot;TBL_RIGHT&quot;.&quot;engine&quot; AS &quot;engine&quot; ## FROM datawarehouse.vflight AS &quot;TBL_LEFT&quot; ## LEFT JOIN &quot;planes&quot; AS &quot;TBL_RIGHT&quot; ## ON (&quot;TBL_LEFT&quot;.&quot;tailnum&quot; = &quot;TBL_RIGHT&quot;.&quot;tailnum&quot;) ## ) &quot;raogmwbzgh&quot; ## WHERE (&quot;manufacturer&quot; = &#39;MCDONNELL DOUGLAS&#39;)) &quot;ydrljxkzpa&quot; ## GROUP BY &quot;tailnum&quot;) &quot;kqyzgozqmv&quot; ## ## &lt;PLAN&gt; ## Aggregate (cost=295342.72..295342.73 rows=1 width=56) ## -&gt; GroupAggregate (cost=295099.20..295242.64 rows=5004 width=14) ## Group Key: &quot;TBL_LEFT&quot;.tailnum ## -&gt; Sort (cost=295099.20..295130.33 rows=12454 width=6) ## Sort Key: &quot;TBL_LEFT&quot;.tailnum ## -&gt; Hash Join (cost=70.61..294252.06 rows=12454 width=6) ## Hash Cond: (&quot;TBL_LEFT&quot;.tailnum = &quot;TBL_RIGHT&quot;.tailnum) ## -&gt; Seq Scan on flight &quot;TBL_LEFT&quot; (cost=0.00..267764.93 rows=7011193 width=17) ## -&gt; Hash (cost=70.50..70.50 rows=9 width=32) ## -&gt; Seq Scan on planes &quot;TBL_RIGHT&quot; (cost=0.00..70.50 rows=9 width=32) ## Filter: (manufacturer = &#39;MCDONNELL DOUGLAS&#39;::text) Disconnect from the database dbDisconnect(con) "],
["data-visualizations.html", "4 Data Visualizations 4.1 Simple plot 4.2 Plot in one code segment 4.3 Plot specific data segments 4.4 Plot correlations 4.5 Two or more queries 4.6 Visualize using dbplot 4.7 Plot a different aggregation 4.8 Create a histogram 4.9 Raster plot 4.10 Using the calculate functions 4.11 Under the hood (II)", " 4 Data Visualizations 4.1 Simple plot Practice pushing the calculations to the database Use collect() bring back the aggregated results into a “pass-through” variable called by_month by_month &lt;- flights %&gt;% group_by(month) %&gt;% tally() %&gt;% mutate(n = as.numeric(n)) %&gt;% collect() head(by_month) ## # A tibble: 6 x 2 ## month n ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 605765 ## 2 2 569236 ## 3 3 616090 ## 4 4 598126 ## 5 5 606293 ## 6 6 608665 Plot results using ggplot2 library(ggplot2) ggplot(by_month) + geom_line(aes(x = month, y = n)) 4.2 Plot in one code segment Practice going from dplyr to ggplot2 without using pass-through variable, great for EDA Using the code from the previous section, create a single piped code set which also creates the plot flights %&gt;% group_by(month) %&gt;% tally() %&gt;% mutate(n = as.numeric(n)) %&gt;% collect() %&gt;% ggplot() + # &lt; Don&#39;t forget to switch to `+` geom_line(aes(x = month, y = n)) Change the aggregation to the average of arrdelay. Tip: Use x as the summarize variable flights %&gt;% group_by(month) %&gt;% summarise(x = mean(arrdelay, na.rm = TRUE)) %&gt;% mutate(x = as.numeric(x)) %&gt;% collect() %&gt;% ggplot() + geom_line(aes(x = month, y = x)) Plot the average distance. Copy the code from the previous exercise and change the variable flights %&gt;% group_by(month) %&gt;% summarise(x = mean(distance, na.rm = TRUE)) %&gt;% mutate(x = as.numeric(x)) %&gt;% collect() %&gt;% ggplot() + geom_line(aes(x = month, y = x)) 4.3 Plot specific data segments Combine skills from previous units to create more sophisticated plots Start with getting the top 5 carriers flights %&gt;% group_by(uniquecarrier) %&gt;% tally() %&gt;% arrange(desc(n)) %&gt;% head(5) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Ordered by: desc(n) ## uniquecarrier n ## &lt;chr&gt; &lt;S3: integer64&gt; ## 1 WN 1201754 ## 2 AA 604885 ## 3 OO 567159 ## 4 MQ 490693 ## 5 US 453589 Pipe the top 5 carriers to a plot flights %&gt;% group_by(uniquecarrier) %&gt;% tally() %&gt;% mutate(n = as.numeric(n)) %&gt;% arrange(desc(n)) %&gt;% head(5) %&gt;% collect() %&gt;% ggplot() + geom_col(aes(x = uniquecarrier, y = n)) Improve the plot’s look flights %&gt;% group_by(uniquecarrier) %&gt;% tally() %&gt;% mutate(n = as.numeric(n)) %&gt;% arrange(desc(n)) %&gt;% head(5) %&gt;% collect() %&gt;% ggplot() + #Don&#39;t forget to switch to `+` geom_col(aes(x = forcats::fct_reorder(uniquecarrier, n), # Order by n y = n, fill = n), # Add fill show.legend = FALSE) + # Turn legend off scale_y_continuous(labels = scales::comma) + # Add commas to axis label numbers coord_flip() + # Rotate cols into rows labs(title = &quot;Top 5 Carriers&quot;, subtitle = &quot;Source: Datawarehouse&quot;, x = &quot;Carrier Name&quot;, y = &quot;# of Flights&quot;) 4.4 Plot correlations Use the corrr package to plot correlations Correlate select numeric columns from the flights table library(corrr) flights_cor &lt;- flights %&gt;% select(contains(&quot;delay&quot;)) %&gt;% correlate(use = &quot;complete.obs&quot;) ## ## Correlation method: &#39;pearson&#39; ## Missing treated using: &#39;complete.obs&#39; Visualize the correlations flights_cor %&gt;% rplot() Visualize correlation network flights_cor %&gt;% network_plot(min_cor = .15) 4.5 Two or more queries Learn how to use pull() to pass a set of values to be used on a secondary query Use pull() to get the top 5 carriers loaded in a vector top5 &lt;- flights %&gt;% group_by(uniquecarrier) %&gt;% tally() %&gt;% arrange(desc(n)) %&gt;% head(5) %&gt;% pull(uniquecarrier) top5 ## [1] &quot;WN&quot; &quot;AA&quot; &quot;OO&quot; &quot;MQ&quot; &quot;US&quot; Use %in% to pass the top5 vector to a filter flights %&gt;% filter(uniquecarrier %in% top5) ## # Source: lazy query [?? x 31] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## flightid year month dayofmonth dayofweek deptime crsdeptime arrtime ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3654535 2008 7 18 5 641 645 726 ## 2 3654536 2008 7 18 5 1304 1305 1341 ## 3 3654537 2008 7 18 5 1938 1755 2018 ## 4 3654538 2008 7 18 5 1935 1935 2127 ## 5 3654539 2008 7 18 5 959 1000 1158 ## 6 3654540 2008 7 18 5 1531 1530 1651 ## 7 3654541 2008 7 18 5 826 830 1016 ## 8 3654542 2008 7 18 5 1045 1045 1356 ## 9 3654543 2008 7 18 5 1502 1405 2025 ## 10 3654544 2008 7 18 5 959 1000 1001 ## # … with more rows, and 23 more variables: crsarrtime &lt;dbl&gt;, ## # uniquecarrier &lt;chr&gt;, flightnum &lt;dbl&gt;, tailnum &lt;chr&gt;, ## # actualelapsedtime &lt;dbl&gt;, crselapsedtime &lt;dbl&gt;, airtime &lt;dbl&gt;, ## # arrdelay &lt;dbl&gt;, depdelay &lt;dbl&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # distance &lt;dbl&gt;, taxiin &lt;dbl&gt;, taxiout &lt;dbl&gt;, cancelled &lt;dbl&gt;, ## # cancellationcode &lt;chr&gt;, diverted &lt;dbl&gt;, carrierdelay &lt;dbl&gt;, ## # weatherdelay &lt;dbl&gt;, nasdelay &lt;dbl&gt;, securitydelay &lt;dbl&gt;, ## # lateaircraftdelay &lt;dbl&gt;, score &lt;int&gt; Group by carrier and get the average arrival delay flights %&gt;% filter(uniquecarrier %in% top5) %&gt;% group_by(uniquecarrier) %&gt;% summarise(n = mean(arrdelay, na.rm = TRUE)) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## uniquecarrier n ## &lt;chr&gt; &lt;dbl&gt; ## 1 AA 12.6 ## 2 MQ 9.89 ## 3 OO 6.60 ## 4 US 2.85 ## 5 WN 5.18 Copy the final ggplot() code from the Plot specific data segments section. Update the y labs. flights %&gt;% filter(uniquecarrier %in% top5) %&gt;% group_by(uniquecarrier) %&gt;% summarise(n = mean(arrdelay, na.rm = TRUE)) %&gt;% # From previous section ---------------------------------------------- collect() %&gt;% ggplot() + #Don&#39;t forget to switch to `+` geom_col(aes(x = forcats::fct_reorder(uniquecarrier, n), # Order by n y = n, fill = n), # Add fill show.legend = FALSE) + # Turn legend off coord_flip() + # Rotate cols into rows labs(title = &quot;Top 5 Carriers&quot;, subtitle = &quot;Source: Datawarehouse&quot;, x = &quot;Carrier Name&quot;, y = &quot;Average Delay&quot;) 4.6 Visualize using dbplot Review how to use dbplot to make it easier to plot with databases Install and load dbplot library(dbplot) Create a line plot using the helper function dbplot_line() flights %&gt;% count(month) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## month n ## &lt;dbl&gt; &lt;S3: integer64&gt; ## 1 1 605765 ## 2 2 569236 ## 3 3 616090 ## 4 4 598126 ## 5 5 606293 ## 6 6 608665 ## 7 7 627931 ## 8 8 612279 ## 9 9 540908 ## 10 10 556205 ## # … with more rows flights %&gt;% dbplot_line(month) ## Don&#39;t know how to automatically pick scale for object of type integer64. Defaulting to continuous. ## Warning: Removed 12 rows containing missing values (geom_path). flights %&gt;% db_compute_bins(month) ## # A tibble: 12 x 2 ## month count ## &lt;dbl&gt; &lt;S3: integer64&gt; ## 1 8.7 540908 ## 2 6.87 627931 ## 3 3.93 598126 ## 4 4.67 606293 ## 5 1.73 569236 ## 6 10.9 523272 ## 7 2.83 616090 ## 8 11.6 544958 ## 9 5.77 608665 ## 10 9.80 556205 ## 11 1 605765 ## 12 7.97 612279 Update the plot’s labels flights %&gt;% dbplot_line(month) + labs(title = &quot;Monthly flights&quot;, x = &quot;Month&quot;, y = &quot;Number of flights&quot;) ## Don&#39;t know how to automatically pick scale for object of type integer64. Defaulting to continuous. ## Warning: Removed 12 rows containing missing values (geom_path). 4.7 Plot a different aggregation dbplot allows for aggregate functions, other than record count, to be used for plotting Plot the average departure delay by day of week flights %&gt;% dbplot_bar(dayofweek, mean(depdelay, na.rm = TRUE)) Change the day numbers to day name labels flights %&gt;% dbplot_bar(dayofweek, mean(depdelay, na.rm = TRUE)) + scale_x_continuous( labels = c(&quot;Mon&quot;, &quot;Tue&quot;, &quot;Wed&quot;, &quot;Thu&quot;, &quot;Fri&quot;, &quot;Sat&quot;, &quot;Sun&quot;), breaks = 1:7 ) 4.8 Create a histogram Use the package’s function to easily create a histogram Use the dbplot_histogram() to build the histogram flights %&gt;% dbplot_histogram(distance) ## Don&#39;t know how to automatically pick scale for object of type integer64. Defaulting to continuous. ## Warning: Removed 27 rows containing missing values (position_stack). Adjust the binwidth to 300 flights %&gt;% dbplot_histogram(distance, binwidth = 300) ## Don&#39;t know how to automatically pick scale for object of type integer64. Defaulting to continuous. ## Warning: Removed 16 rows containing missing values (position_stack). 4.9 Raster plot Use a dbplot_raster() to visualize deptime versus depdelay flights %&gt;% dbplot_raster(deptime, arrtime) ## Warning: Removed 83 rows containing missing values (geom_raster). Change the plot’s resolution to 500 flights %&gt;% dbplot_raster(deptime, arrtime, resolution = 500) ## Warning: Removed 293 rows containing missing values (geom_raster). 4.10 Using the calculate functions Use the db_compute_raster() function to get the underlying results that feed the plot departure &lt;- flights %&gt;% db_compute_raster(deptime, arrtime) departure ## # A tibble: 3,602 x 3 ## deptime arrtime `n()` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 NA NA 136246 ## 2 1057. 1848. 60 ## 3 625. 841. 12271 ## 4 697. 1392. 608 ## 5 817. 1105. 13782 ## 6 721. 1248. 543 ## 7 649. 1488. 552 ## 8 1512. 2256. 59 ## 9 601. 649. 5476 ## 10 1680. 2112. 309 ## # … with 3,592 more rows Plot the results “manually” departure %&gt;% filter(`n()` &gt; 1000) %&gt;% ggplot() + geom_raster(aes(x = deptime, y = arrtime, fill = `n()`)) ## Warning: Removed 1 rows containing missing values (geom_raster). 4.11 Under the hood (II) Review how dbplot pushes histogram and raster calculations to the database Use the db_bin() command to see the resulting tidy eval formula db_bin(field) ## (((max(field, na.rm = TRUE) - min(field, na.rm = TRUE))/30) * ## ifelse(as.integer(floor((field - min(field, na.rm = TRUE))/((max(field, ## na.rm = TRUE) - min(field, na.rm = TRUE))/30))) == 30, ## as.integer(floor((field - min(field, na.rm = TRUE))/((max(field, ## na.rm = TRUE) - min(field, na.rm = TRUE))/30))) - ## 1, as.integer(floor((field - min(field, na.rm = TRUE))/((max(field, ## na.rm = TRUE) - min(field, na.rm = TRUE))/30))))) + ## min(field, na.rm = TRUE) Use translate_sql() and simulate_odbc_postgresql() to see an example of what the resulting SQL statement looks like translate_sql(!! db_bin(field), con = simulate_odbc_postgresql()) ## &lt;SQL&gt; (((max(`field`) OVER () - min(`field`) OVER ()) / 30.0) * CASE WHEN (CAST(FLOOR((`field` - min(`field`) OVER ()) / ((max(`field`) OVER () - min(`field`) OVER ()) / 30.0)) AS INTEGER) = 30.0) THEN (CAST(FLOOR((`field` - min(`field`) OVER ()) / ((max(`field`) OVER () - min(`field`) OVER ()) / 30.0)) AS INTEGER) - 1.0) WHEN NOT(CAST(FLOOR((`field` - min(`field`) OVER ()) / ((max(`field`) OVER () - min(`field`) OVER ()) / 30.0)) AS INTEGER) = 30.0) THEN (CAST(FLOOR((`field` - min(`field`) OVER ()) / ((max(`field`) OVER () - min(`field`) OVER ()) / 30.0)) AS INTEGER)) END) + min(`field`) OVER () Disconnect from the database dbDisconnect(con) "],
["modeling.html", "5 Modeling 5.1 SQL Native sampling 5.2 Sample with ID 5.3 Sample manually 5.4 Create a model &amp; test 5.5 Score inside database 5.6 Parsed model 5.7 Model inside the database", " 5 Modeling 5.1 SQL Native sampling Use PostgreSQL TABLESAMPLE clause Find out the class of the object returned by show_query(). Test with table_flights. table_flights %&gt;% show_query() %&gt;% class() ## &lt;SQL&gt; ## SELECT * ## FROM datawarehouse.flight ## [1] &quot;tbl_PostgreSQL&quot; &quot;tbl_dbi&quot; &quot;tbl_sql&quot; &quot;tbl_lazy&quot; ## [5] &quot;tbl&quot; Find out the class of the object returned by remote_query(). Test with table_flights. table_flights %&gt;% remote_query() %&gt;% class() ## [1] &quot;sql&quot; &quot;character&quot; Run remote_query() again table_flights remote_query(table_flights) ## &lt;SQL&gt; SELECT * ## FROM datawarehouse.flight Use build_sql() to paste together the results of the remote_query() operation and &quot; TABLESAMPLE SYSTEM (0.1)&quot; build_sql(remote_query(table_flights), &quot; TABLESAMPLE SYSTEM (0.1)&quot;) ## &lt;SQL&gt; SELECT * ## FROM datawarehouse.flight TABLESAMPLE SYSTEM (0.1) Use build_sql() and remote_query() to combine a the dplyr command with a custom SQL statement sql_sample &lt;- dbGetQuery(con, build_sql(remote_query(table_flights), &quot; TABLESAMPLE SYSTEM (0.1)&quot;)) Preview the sample data sql_sample ## flightid year month dayofmonth dayofweek deptime crsdeptime arrtime ## 1 6219 2008 1 5 6 1541 1520 1625 ## 2 6220 2008 1 5 6 1313 1150 1524 ## 3 6221 2008 1 5 6 1648 1650 1902 ## 4 6222 2008 1 5 6 705 705 917 ## 5 6223 2008 1 5 6 1750 1735 2107 ## 6 6224 2008 1 5 6 626 625 925 ## 7 6225 2008 1 5 6 1404 1355 1721 ## 8 6226 2008 1 5 6 1123 1115 1426 ## 9 6227 2008 1 5 6 1857 1840 1949 ## 10 6228 2008 1 5 6 1216 1200 1306 ## 11 6229 2008 1 5 6 700 700 757 ## 12 6230 2008 1 5 6 1100 1100 1207 ## 13 6231 2008 1 5 6 1536 1530 1640 ## 14 6232 2008 1 5 6 1856 1855 1958 ## 15 6233 2008 1 5 6 1746 1750 1850 ## 16 6234 2008 1 5 6 47 2040 151 ## 17 6235 2008 1 5 6 941 930 1050 ## 18 6236 2008 1 5 6 1636 1640 1740 ## 19 6237 2008 1 5 6 759 745 908 ## 20 6238 2008 1 5 6 1331 1325 1432 ## 21 6239 2008 1 5 6 1419 1405 1525 ## 22 6240 2008 1 5 6 652 650 748 ## 23 6241 2008 1 5 6 1510 1510 1608 ## 24 6242 2008 1 5 6 910 915 1009 ## 25 6243 2008 1 5 6 2059 2025 2159 ## 26 6244 2008 1 5 6 1131 1125 1229 ## 27 6245 2008 1 5 6 1743 1700 1844 ## 28 6246 2008 1 5 6 905 905 1146 ## 29 6247 2008 1 5 6 1517 1510 1747 ## 30 6248 2008 1 5 6 859 845 1206 ## 31 6249 2008 1 5 6 1553 1535 1828 ## 32 6250 2008 1 5 6 1029 1025 1307 ## crsarrtime uniquecarrier flightnum tailnum actualelapsedtime ## 1 1610 WN 2019 N676SW 44 ## 2 1425 WN 733 N794SW 131 ## 3 1925 WN 2103 N270WN 134 ## 4 940 WN 3224 N404WN 132 ## 5 2055 WN 489 N470WN 317 ## 6 940 WN 1866 N245WN 299 ## 7 1710 WN 2359 N257WN 317 ## 8 1425 WN 2442 N775SW 303 ## 9 1940 WN 310 N619SW 52 ## 10 1300 WN 1013 N357SW 50 ## 11 800 WN 3833 N787SA 57 ## 12 1205 WN 99 N253WN 67 ## 13 1640 WN 257 N420WN 64 ## 14 2005 WN 394 N756SA 62 ## 15 1900 WN 406 N346SW 64 ## 16 2145 WN 505 N435WN 64 ## 17 1040 WN 896 N793SA 69 ## 18 1750 WN 1947 N745SW 64 ## 19 855 WN 2355 N775SW 69 ## 20 1430 WN 2621 N637SW 61 ## 21 1515 WN 3047 N266WN 66 ## 22 755 WN 122 N242WN 56 ## 23 1615 WN 182 N684WN 58 ## 24 1020 WN 606 N672SW 59 ## 25 2130 WN 683 N551WN 60 ## 26 1230 WN 1414 N364SW 58 ## 27 1805 WN 3046 N723SW 61 ## 28 1155 WN 143 N480WN 161 ## 29 1800 WN 1743 N390SW 150 ## 30 1135 WN 3679 N451WN 367 ## 31 1835 WN 572 N461WN 215 ## 32 1330 WN 710 N354SW 218 ## crselapsedtime airtime arrdelay depdelay origin dest distance taxiin ## 1 50 33 15 21 BWI ORF 159 3 ## 2 155 117 59 83 BWI PBI 883 5 ## 3 155 120 -23 -2 BWI PBI 883 4 ## 4 155 116 -23 0 BWI PBI 883 4 ## 5 320 295 12 15 BWI PHX 1999 13 ## 6 315 289 -15 1 BWI PHX 1999 3 ## 7 315 286 11 9 BWI PHX 1999 16 ## 8 310 288 1 8 BWI PHX 1999 6 ## 9 60 39 9 17 BWI PIT 210 6 ## 10 60 37 6 16 BWI PIT 210 6 ## 11 60 38 -3 0 BWI PIT 210 7 ## 12 65 53 2 0 BWI PVD 328 5 ## 13 70 50 0 6 BWI PVD 328 6 ## 14 70 50 -7 1 BWI PVD 328 5 ## 15 70 49 -10 -4 BWI PVD 328 5 ## 16 65 51 246 247 BWI PVD 328 5 ## 17 70 52 10 11 BWI PVD 328 4 ## 18 70 50 -10 -4 BWI PVD 328 5 ## 19 70 53 13 14 BWI PVD 328 6 ## 20 65 50 2 6 BWI PVD 328 4 ## 21 70 51 10 14 BWI PVD 328 5 ## 22 65 44 -7 2 BWI RDU 255 4 ## 23 65 44 -7 0 BWI RDU 255 4 ## 24 65 47 -11 -5 BWI RDU 255 4 ## 25 65 46 29 34 BWI RDU 255 5 ## 26 65 46 -1 6 BWI RDU 255 4 ## 27 65 46 39 43 BWI RDU 255 5 ## 28 170 132 -9 0 BWI RSW 919 3 ## 29 170 136 -13 7 BWI RSW 919 4 ## 30 350 351 31 14 BWI SAN 2295 4 ## 31 240 203 -7 18 BWI SAT 1407 3 ## 32 245 209 -23 4 BWI SAT 1407 2 ## taxiout cancelled cancellationcode diverted carrierdelay weatherdelay ## 1 8 0 &lt;NA&gt; 0 15 0 ## 2 9 0 &lt;NA&gt; 0 11 0 ## 3 10 0 &lt;NA&gt; 0 NA NA ## 4 12 0 &lt;NA&gt; 0 NA NA ## 5 9 0 &lt;NA&gt; 0 NA NA ## 6 7 0 &lt;NA&gt; 0 NA NA ## 7 15 0 &lt;NA&gt; 0 NA NA ## 8 9 0 &lt;NA&gt; 0 NA NA ## 9 7 0 &lt;NA&gt; 0 NA NA ## 10 7 0 &lt;NA&gt; 0 NA NA ## 11 12 0 &lt;NA&gt; 0 NA NA ## 12 9 0 &lt;NA&gt; 0 NA NA ## 13 8 0 &lt;NA&gt; 0 NA NA ## 14 7 0 &lt;NA&gt; 0 NA NA ## 15 10 0 &lt;NA&gt; 0 NA NA ## 16 8 0 &lt;NA&gt; 0 3 0 ## 17 13 0 &lt;NA&gt; 0 NA NA ## 18 9 0 &lt;NA&gt; 0 NA NA ## 19 10 0 &lt;NA&gt; 0 NA NA ## 20 7 0 &lt;NA&gt; 0 NA NA ## 21 10 0 &lt;NA&gt; 0 NA NA ## 22 8 0 &lt;NA&gt; 0 NA NA ## 23 10 0 &lt;NA&gt; 0 NA NA ## 24 8 0 &lt;NA&gt; 0 NA NA ## 25 9 0 &lt;NA&gt; 0 12 0 ## 26 8 0 &lt;NA&gt; 0 NA NA ## 27 10 0 &lt;NA&gt; 0 17 0 ## 28 26 0 &lt;NA&gt; 0 NA NA ## 29 10 0 &lt;NA&gt; 0 NA NA ## 30 12 0 &lt;NA&gt; 0 14 0 ## 31 9 0 &lt;NA&gt; 0 NA NA ## 32 7 0 &lt;NA&gt; 0 NA NA ## nasdelay securitydelay lateaircraftdelay score ## 1 0 0 0 NA ## 2 0 0 48 NA ## 3 NA NA NA NA ## 4 NA NA NA NA ## 5 NA NA NA NA ## 6 NA NA NA NA ## 7 NA NA NA NA ## 8 NA NA NA NA ## 9 NA NA NA NA ## 10 NA NA NA NA ## 11 NA NA NA NA ## 12 NA NA NA NA ## 13 NA NA NA NA ## 14 NA NA NA NA ## 15 NA NA NA NA ## 16 0 0 243 NA ## 17 NA NA NA NA ## 18 NA NA NA NA ## 19 NA NA NA NA ## 20 NA NA NA NA ## 21 NA NA NA NA ## 22 NA NA NA NA ## 23 NA NA NA NA ## 24 NA NA NA NA ## 25 0 0 17 NA ## 26 NA NA NA NA ## 27 0 0 22 NA ## 28 NA NA NA NA ## 29 NA NA NA NA ## 30 17 0 0 NA ## 31 NA NA NA NA ## 32 NA NA NA NA ## [ reached getOption(&quot;max.print&quot;) -- omitted 7401 rows ] Test the efficacy of the sampling using dbplot_histogram() and comparing to the histogram produced in the Visualization chapter. dbplot_histogram(sql_sample, distance) 5.2 Sample with ID Use a record’s unique ID to produce a sample Summarize with max() and min() to get the upper and lower bound of flightid limit &lt;- table_flights %&gt;% summarise( max = max(flightid, na.rm = TRUE), min = min(flightid, na.rm = TRUE) ) %&gt;% collect() Use sample() to get 0.1% of IDs sampling &lt;- sample( limit$min:limit$max, round((limit$max -limit$min) * 0.001) ) Use %in% to match the sample IDs in table_flights table id_sample &lt;- table_flights %&gt;% filter(flightid %in% sampling) %&gt;% collect() Test the efficacy of the sampling using dbplot_histogram() and comparing to the histogram produced in the Visualization chapter. dbplot_histogram(id_sample, distance) 5.3 Sample manually Use row_number(), sample() and map_df() to create a sample data set Create a filtered data set with January’s data db_month &lt;- table_flights %&gt;% filter(month == 1) Get the row count, collect and save the results to a variable rows &lt;- db_month %&gt;% tally() %&gt;% pull() %&gt;% as.integer() rows ## [1] 605765 Use row_number() to create a new column to number each row db_month &lt;- db_month %&gt;% mutate(row = row_number()) Create a random set of 600 numbers, limited by the number of rows sampling &lt;- sample(1:rows, 600) Use %in% to filter the matched sample row IDs with the random set db_month &lt;- db_month %&gt;% filter(row %in% sampling) Verify number of rows tally(db_month) ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## n ## &lt;S3: integer64&gt; ## 1 600 Create a function with the previous steps, but replacing the month number with an argument. Collect the data at the end sample_segment &lt;- function(x, size = 600) { db_month &lt;- table_flights %&gt;% filter(month == x) rows &lt;- db_month %&gt;% tally() %&gt;% pull() %&gt;% as.integer() db_month &lt;- db_month %&gt;% mutate(row = row_number()) sampling &lt;- sample(1:rows, size) db_month %&gt;% filter(row %in% sampling) %&gt;% collect() } Test the function head(sample_segment(3), 100) ## # A tibble: 100 x 32 ## flightid year month dayofmonth dayofweek deptime crsdeptime arrtime ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1177383 2008 3 3 1 720 720 912 ## 2 1178149 2008 3 4 2 651 650 807 ## 3 1178829 2008 3 4 2 856 900 952 ## 4 1179167 2008 3 4 2 759 800 807 ## 5 1179369 2008 3 4 2 709 710 910 ## 6 1183494 2008 3 5 3 2054 2100 11 ## 7 1184306 2008 3 5 3 731 735 932 ## 8 1185885 2008 3 6 4 1000 1000 1050 ## 9 1188572 2008 3 7 5 1641 1620 1757 ## 10 1191340 2008 3 7 5 833 830 956 ## # … with 90 more rows, and 24 more variables: crsarrtime &lt;dbl&gt;, ## # uniquecarrier &lt;chr&gt;, flightnum &lt;dbl&gt;, tailnum &lt;chr&gt;, ## # actualelapsedtime &lt;dbl&gt;, crselapsedtime &lt;dbl&gt;, airtime &lt;dbl&gt;, ## # arrdelay &lt;dbl&gt;, depdelay &lt;dbl&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # distance &lt;dbl&gt;, taxiin &lt;dbl&gt;, taxiout &lt;dbl&gt;, cancelled &lt;dbl&gt;, ## # cancellationcode &lt;chr&gt;, diverted &lt;dbl&gt;, carrierdelay &lt;dbl&gt;, ## # weatherdelay &lt;dbl&gt;, nasdelay &lt;dbl&gt;, securitydelay &lt;dbl&gt;, ## # lateaircraftdelay &lt;dbl&gt;, score &lt;int&gt;, row &lt;S3: integer64&gt; Use map_df() to run the function for each month strat_sample &lt;- 1:12 %&gt;% map_df(~sample_segment(.x)) Verify sample with a dbplot_histogram() dbplot_histogram(strat_sample, distance) 5.4 Create a model &amp; test Prepare a model data set. Using case_when() create a field called season and assign based model_data &lt;- strat_sample %&gt;% mutate( season = case_when( month &gt;= 3 &amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp; month &lt;= 8 ~ &quot;Summer&quot;, month &gt;= 9 &amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot; ) ) %&gt;% select(arrdelay, season, depdelay) Create a simple lm() model against arrdelay model_lm &lt;- lm(arrdelay ~ . , data = model_data) summary(model_lm) ## ## Call: ## lm(formula = arrdelay ~ ., data = model_data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -73.161 -7.603 -1.642 5.892 195.394 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3.215076 0.324456 -9.909 &lt; 2e-16 *** ## seasonSpring 1.820816 0.459621 3.962 7.52e-05 *** ## seasonSummer 1.272814 0.459332 2.771 0.0056 ** ## seasonWinter 2.243866 0.462941 4.847 1.28e-06 *** ## depdelay 1.002297 0.004775 209.904 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 13.65 on 7038 degrees of freedom ## (157 observations deleted due to missingness) ## Multiple R-squared: 0.8642, Adjusted R-squared: 0.8641 ## F-statistic: 1.12e+04 on 4 and 7038 DF, p-value: &lt; 2.2e-16 Create a test data set by combining the sampling and model data set routines test_sample &lt;- 1:12 %&gt;% map_df(~sample_segment(.x, 100)) %&gt;% mutate( season = case_when( month &gt;= 3 &amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp; month &lt;= 8 ~ &quot;Summer&quot;, month &gt;= 9 &amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot; ) ) %&gt;% select(arrdelay, season, depdelay) Run a simple routine to check accuracy test_sample %&gt;% mutate(p = predict(model_lm, test_sample), over = abs(p - arrdelay) &lt; 10) %&gt;% group_by(over) %&gt;% tally() %&gt;% mutate(percent = round(n / sum(n), 2)) ## # A tibble: 3 x 3 ## over n percent ## &lt;lgl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 FALSE 397 0.33 ## 2 TRUE 769 0.64 ## 3 NA 34 0.03 5.5 Score inside database Learn about tidypredict to run predictions inside the database Load the library, and see the results of passing the model as an argument to tidypredict_fit() library(tidypredict) tidypredict_fit(model_lm) ## -3.21507610390455 + (ifelse(season == &quot;Spring&quot;, 1, 0) * 1.82081568135116) + ## (ifelse(season == &quot;Summer&quot;, 1, 0) * 1.27281431978887) + (ifelse(season == ## &quot;Winter&quot;, 1, 0) * 2.24386585576143) + (depdelay * 1.00229721826541) Use tidypredict_sql() to see the resulting SQL statement tidypredict_sql(model_lm, con) ## &lt;SQL&gt; -3.21507610390455 + (CASE WHEN (&quot;season&quot; = &#39;Spring&#39;) THEN (1.0) WHEN NOT(&quot;season&quot; = &#39;Spring&#39;) THEN (0.0) END * 1.82081568135116) + (CASE WHEN (&quot;season&quot; = &#39;Summer&#39;) THEN (1.0) WHEN NOT(&quot;season&quot; = &#39;Summer&#39;) THEN (0.0) END * 1.27281431978887) + (CASE WHEN (&quot;season&quot; = &#39;Winter&#39;) THEN (1.0) WHEN NOT(&quot;season&quot; = &#39;Winter&#39;) THEN (0.0) END * 2.24386585576143) + (&quot;depdelay&quot; * 1.00229721826541) Run the prediction inside dplyr by piping the same transformations into tidypredict_to_column(), but starting with table_flights table_flights %&gt;% filter(month == 2, dayofmonth == 1) %&gt;% mutate( season = case_when( month &gt;= 3 &amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp; month &lt;= 8 ~ &quot;Summer&quot;, month &gt;= 9 &amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot; ) ) %&gt;% select( season, depdelay) %&gt;% tidypredict_to_column(model_lm) %&gt;% head() ## # Source: lazy query [?? x 3] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## season depdelay fit ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Winter 19 18.1 ## 2 Winter NA NA ## 3 Winter -5 -5.98 ## 4 Winter -9 -9.99 ## 5 Winter -6 -6.98 ## 6 Winter 50 49.1 View the SQL behind the dplyr command with remote_query() table_flights %&gt;% filter(month == 2, dayofmonth == 1) %&gt;% mutate( season = case_when( month &gt;= 3 &amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp; month &lt;= 8 ~ &quot;Summer&quot;, month &gt;= 9 &amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot; ) ) %&gt;% select( season, depdelay) %&gt;% tidypredict_to_column(model_lm) %&gt;% remote_query() ## &lt;SQL&gt; SELECT &quot;season&quot;, &quot;depdelay&quot;, -3.21507610390455 + (CASE WHEN (&quot;season&quot; = &#39;Spring&#39;) THEN (1.0) WHEN NOT(&quot;season&quot; = &#39;Spring&#39;) THEN (0.0) END * 1.82081568135116) + (CASE WHEN (&quot;season&quot; = &#39;Summer&#39;) THEN (1.0) WHEN NOT(&quot;season&quot; = &#39;Summer&#39;) THEN (0.0) END * 1.27281431978887) + (CASE WHEN (&quot;season&quot; = &#39;Winter&#39;) THEN (1.0) WHEN NOT(&quot;season&quot; = &#39;Winter&#39;) THEN (0.0) END * 2.24386585576143) + (&quot;depdelay&quot; * 1.00229721826541) AS &quot;fit&quot; ## FROM (SELECT &quot;season&quot;, &quot;depdelay&quot; ## FROM (SELECT &quot;flightid&quot;, &quot;year&quot;, &quot;month&quot;, &quot;dayofmonth&quot;, &quot;dayofweek&quot;, &quot;deptime&quot;, &quot;crsdeptime&quot;, &quot;arrtime&quot;, &quot;crsarrtime&quot;, &quot;uniquecarrier&quot;, &quot;flightnum&quot;, &quot;tailnum&quot;, &quot;actualelapsedtime&quot;, &quot;crselapsedtime&quot;, &quot;airtime&quot;, &quot;arrdelay&quot;, &quot;depdelay&quot;, &quot;origin&quot;, &quot;dest&quot;, &quot;distance&quot;, &quot;taxiin&quot;, &quot;taxiout&quot;, &quot;cancelled&quot;, &quot;cancellationcode&quot;, &quot;diverted&quot;, &quot;carrierdelay&quot;, &quot;weatherdelay&quot;, &quot;nasdelay&quot;, &quot;securitydelay&quot;, &quot;lateaircraftdelay&quot;, &quot;score&quot;, CASE ## WHEN (&quot;month&quot; &gt;= 3.0 AND &quot;month&quot; &lt;= 5.0) THEN (&#39;Spring&#39;) ## WHEN (&quot;month&quot; &gt;= 6.0 AND &quot;month&quot; &lt;= 8.0) THEN (&#39;Summer&#39;) ## WHEN (&quot;month&quot; &gt;= 9.0 AND &quot;month&quot; &lt;= 11.0) THEN (&#39;Fall&#39;) ## WHEN (&quot;month&quot; = 12.0 OR &quot;month&quot; &lt;= 2.0) THEN (&#39;Winter&#39;) ## END AS &quot;season&quot; ## FROM (SELECT * ## FROM datawarehouse.flight ## WHERE ((&quot;month&quot; = 2.0) AND (&quot;dayofmonth&quot; = 1.0))) &quot;rdmsrldtdf&quot;) &quot;xsktnwfckl&quot;) &quot;pifkbjpiqq&quot; Compare predictions to ensure results are within range using tidypredict_test() test &lt;- tidypredict_test(model_lm) test ## tidypredict test results ## Difference threshold: 1e-12 ## ## All results are within the difference threshold View the records that exceeded the threshold test$raw_results %&gt;% filter(fit_threshold) ## [1] rowid fit fit_te fit_diff fit_threshold ## &lt;0 rows&gt; (or 0-length row.names) 5.6 Parsed model Quick review of the model parser Use the parse_model() function to see how tidypredict interprets the model pm &lt;- parse_model(model_lm) With tidypredict_fit(), verify that the resulting table can be used to get the fit formula tidypredict_fit(pm) ## -3.21507610390455 + (ifelse(season == &quot;Spring&quot;, 1, 0) * 1.82081568135116) + ## (ifelse(season == &quot;Summer&quot;, 1, 0) * 1.27281431978887) + (ifelse(season == ## &quot;Winter&quot;, 1, 0) * 2.24386585576143) + (depdelay * 1.00229721826541) Save the parsed model for later use using the yaml package library(yaml) write_yaml(pm, &quot;my_model.yml&quot;) Reload model from the YAML file my_pm &lt;- read_yaml(&quot;my_model.yml&quot;) Use the reloaded model to build the fit formula tidypredict_fit(my_pm) ## -3.2150761 + (ifelse(season == &quot;Spring&quot;, 1, 0) * 1.8208157) + ## (ifelse(season == &quot;Summer&quot;, 1, 0) * 1.2728143) + (ifelse(season == ## &quot;Winter&quot;, 1, 0) * 2.2438659) + (depdelay * 1.0022972) 5.7 Model inside the database Brief intro to modeldb Load modeldb library(modeldb) Use the sampling variable to create a filtered table of table_flights sample &lt;- table_flights %&gt;% filter(flightid %in% sampling) Select deptime, distance and arrdelay from sample and pipe into linear_regression_db(), pass arrdelay as the only argument. sample %&gt;% select(deptime, distance, arrdelay) %&gt;% linear_regression_db(arrdelay) ## # A tibble: 1 x 3 ## `(Intercept)` deptime distance ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.626 0.0105 -0.00383 Using the coefficients from the results, create a new column that multiplies each field against the corresponding coefficient, and adds them all together along with the intercept table_flights %&gt;% head(1000) %&gt;% mutate(pred = --0.6262197 + (deptime * 0.01050023 ) + (distance * -0.003834017 )) %&gt;% select(arrdelay, pred) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## arrdelay pred ## &lt;dbl&gt; &lt;dbl&gt; ## 1 2 6.07 ## 2 -9 1.40 ## 3 -3 7.24 ## 4 -2 14.1 ## 5 8 17.8 ## 6 179 19.5 ## 7 14 12.2 ## 8 -3 19.8 ## 9 1 8.33 ## 10 31 22.8 ## # … with more rows Add dayofweek to the variable selection. Add add_dummy_variables() in between the selection and the linear regression function. Pass dayofweek and c(1:7) to represent the 7 days sample %&gt;% select(deptime, distance, arrdelay, dayofweek) %&gt;% add_dummy_variables(dayofweek, c(1:7)) %&gt;% linear_regression_db(arrdelay, sample_size = 32) ## # A tibble: 1 x 9 ## `(Intercept)` deptime distance dayofweek_2 dayofweek_3 dayofweek_4 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.139 0.0119 -0.00289 -4.48 -8.00 5.70 ## # … with 3 more variables: dayofweek_5 &lt;dbl&gt;, dayofweek_6 &lt;dbl&gt;, ## # dayofweek_7 &lt;dbl&gt; Replace arrdelay with uniquecarrier. Group by uniquecarrier and remove the add_dummy_variable(). sample %&gt;% select(deptime, distance, arrdelay, uniquecarrier) %&gt;% group_by(uniquecarrier) %&gt;% linear_regression_db(arrdelay) ## # A tibble: 20 x 4 ## uniquecarrier `(Intercept)` deptime distance ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AA 13.3 0.00394 -0.00608 ## 2 B6 0.386 0.00933 -0.0105 ## 3 AQ -22.0 0.00904 0.0497 ## 4 F9 3.03 0.00851 -0.0164 ## 5 DL -1.12 -0.00420 0.00418 ## 6 UA -12.2 0.0161 0.00804 ## 7 WN -3.38 0.00929 -0.00400 ## 8 US 9.66 -0.00819 -0.00172 ## 9 MQ 0.129 0.0189 -0.0245 ## 10 OH 7.33 -0.00786 0.0339 ## 11 EV -15.2 0.0132 0.0110 ## 12 9E -3.30 0.00506 0.0117 ## 13 HA -11.6 0.00168 -0.000476 ## 14 NW 20.8 -0.00162 0.00278 ## 15 CO -10.5 0.0194 -0.00732 ## 16 FL 2.54 0.0153 -0.0143 ## 17 OO -19.0 0.0328 -0.00457 ## 18 YV 25.9 -0.0126 0.0313 ## 19 AS -6.54 0.00974 -0.00677 ## 20 XE -49.4 0.0415 0.0223 Pipe the code into ggplot2. Use the intercept for the plot’s x and uniquecarrier for y. Use geom_point() sample %&gt;% select(deptime, distance, arrdelay, uniquecarrier) %&gt;% group_by(uniquecarrier) %&gt;% linear_regression_db(arrdelay) %&gt;% ggplot() + geom_point(aes(`(Intercept)`, uniquecarrier)) "],
["advanced-operations.html", "6 Advanced operations 6.1 Simple wrapper function 6.2 Multiple variables 6.3 Multiple queries 6.4 Multiple queries with an overlaping range", " 6 Advanced operations 6.1 Simple wrapper function Create a function that accepts a value that is passed to a specific dplyr operation The following dplyr operation is fixed to only return the mean of arrtime. The desire is to create a function that returns the mean of any variable passed to it. flights %&gt;% summarise(mean = mean(arrtime, na.rm = TRUE)) ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## mean ## &lt;dbl&gt; ## 1 1481. Load the rlang library, and create a function with one argument. The function will simply return the result of equo() library(rlang) my_mean &lt;- function(x){ x &lt;- enquo(x) x } my_mean(mpg) ## &lt;quosure&gt; ## expr: ^mpg ## env: global Add the summarise() operation, and replace arrtime with !! x library(rlang) my_mean &lt;- function(x){ x &lt;- enquo(x) flights %&gt;% summarise(mean = mean(!! x, na.rm = TRUE)) } Test the function with deptime my_mean(deptime) ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## mean ## &lt;dbl&gt; ## 1 1334. Make the function use what is passed to the x argument as the name of the calculation. Replace mean = with !! quo_name(x) := . my_mean &lt;- function(x){ x &lt;- enquo(x) flights %&gt;% summarise(!! quo_name(x) := mean(!! x, na.rm = TRUE)) } Test the function again with arrtime. The name of the variable should now by arrtime my_mean(arrtime) ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## arrtime ## &lt;dbl&gt; ## 1 1481. Test the function with a formula: arrtime+deptime. my_mean(arrtime+deptime) ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## `arrtime + deptime` ## &lt;dbl&gt; ## 1 2815. Make the function generic by adding a .data argument and replacing flights with .data my_mean &lt;- function(.data, x){ x &lt;- enquo(x) .data %&gt;% summarise(!! quo_name(x) := mean(!! x, na.rm = TRUE)) } The function now behaves more like a dplyr verb. Start with flights and pipe into the function. flights %&gt;% my_mean(arrtime) ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## arrtime ## &lt;dbl&gt; ## 1 1481. Test the function with a different data set. Use mtcars and mpg as the x argument. mtcars %&gt;% my_mean(mpg) ## mpg ## 1 20.09062 Clean up the function by removing the pipe my_mean &lt;- function(.data, x){ x &lt;- enquo(x) summarise( .data, !! quo_name(x) := mean(!! x, na.rm = TRUE) ) } Test again, no visible changes should be there for the results mtcars %&gt;% my_mean(mpg) ## mpg ## 1 20.09062 Because the function only uses dplyr operations, show_query() should work flights %&gt;% my_mean(arrtime) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT AVG(&quot;arrtime&quot;) AS &quot;arrtime&quot; ## FROM datawarehouse.vflight 6.2 Multiple variables Create functions that handle a variable number of arguments. The goal of the exercise is to create an “anti-select()” function. Use … as the second argument of a function called de_select(). Inside the function use enquos() to parse it de_select &lt;- function(.data, ...){ vars &lt;- enquos(...) vars } Test the function using airports airports %&gt;% de_select(airport, airportname) ## [[1]] ## &lt;quosure&gt; ## expr: ^airport ## env: 0x55a78f594a20 ## ## [[2]] ## &lt;quosure&gt; ## expr: ^airportname ## env: 0x55a78f594a20 Add a step to the function that iterates through each quosure and prefixes a minus sign to tell select() to drop that specific field. Use map() for the iteration, and expr() to create the prefixed expression. de_select &lt;- function(.data, ...){ vars &lt;- enquos(...) vars &lt;- map(vars, ~ expr(- !! .x)) vars } Run the same test to view the new results airports %&gt;% de_select(airport, airportname) ## [[1]] ## -~airport ## ## [[2]] ## -~airportname Add the select() step. Use !!! to parse the vars variable inside select() de_select &lt;- function(.data, ...){ vars &lt;- enquos(...) vars &lt;- map(vars, ~ expr(- !! .x)) select( .data, !!! vars ) } Run the test again, this time the operation will take place. airports %&gt;% de_select(airport, airportname) ## # Source: lazy query [?? x 5] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## city state country lat long ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Allentown PA USA 40.7 -75.4 ## 2 Abilene TX USA 32.4 -99.7 ## 3 Albuquerque NM USA 35.0 -107. ## 4 Albany GA USA 31.5 -84.2 ## 5 Nantucket MA USA 41.3 -70.1 ## 6 Waco TX USA 31.6 -97.2 ## 7 Arcata/Eureka CA USA 41.0 -124. ## 8 Atlantic City NJ USA 39.5 -74.6 ## 9 Adak AK USA 51.9 -177. ## 10 Kodiak AK USA 57.7 -152. ## # … with more rows Add a show_query() step to see the resulting SQL airports %&gt;% de_select(airport, airportname) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT &quot;city&quot;, &quot;state&quot;, &quot;country&quot;, &quot;lat&quot;, &quot;long&quot; ## FROM datawarehouse.airport Test the function with a different data set, such as mtcars mtcars %&gt;% de_select(mpg, wt, am) ## cyl disp hp drat qsec vs gear carb ## Mazda RX4 6 160.0 110 3.90 16.46 0 4 4 ## Mazda RX4 Wag 6 160.0 110 3.90 17.02 0 4 4 ## Datsun 710 4 108.0 93 3.85 18.61 1 4 1 ## Hornet 4 Drive 6 258.0 110 3.08 19.44 1 3 1 ## Hornet Sportabout 8 360.0 175 3.15 17.02 0 3 2 ## Valiant 6 225.0 105 2.76 20.22 1 3 1 ## Duster 360 8 360.0 245 3.21 15.84 0 3 4 ## Merc 240D 4 146.7 62 3.69 20.00 1 4 2 ## Merc 230 4 140.8 95 3.92 22.90 1 4 2 ## Merc 280 6 167.6 123 3.92 18.30 1 4 4 ## Merc 280C 6 167.6 123 3.92 18.90 1 4 4 ## Merc 450SE 8 275.8 180 3.07 17.40 0 3 3 ## Merc 450SL 8 275.8 180 3.07 17.60 0 3 3 ## Merc 450SLC 8 275.8 180 3.07 18.00 0 3 3 ## Cadillac Fleetwood 8 472.0 205 2.93 17.98 0 3 4 ## Lincoln Continental 8 460.0 215 3.00 17.82 0 3 4 ## Chrysler Imperial 8 440.0 230 3.23 17.42 0 3 4 ## Fiat 128 4 78.7 66 4.08 19.47 1 4 1 ## Honda Civic 4 75.7 52 4.93 18.52 1 4 2 ## Toyota Corolla 4 71.1 65 4.22 19.90 1 4 1 ## Toyota Corona 4 120.1 97 3.70 20.01 1 3 1 ## Dodge Challenger 8 318.0 150 2.76 16.87 0 3 2 ## AMC Javelin 8 304.0 150 3.15 17.30 0 3 2 ## Camaro Z28 8 350.0 245 3.73 15.41 0 3 4 ## Pontiac Firebird 8 400.0 175 3.08 17.05 0 3 2 ## Fiat X1-9 4 79.0 66 4.08 18.90 1 4 1 ## Porsche 914-2 4 120.3 91 4.43 16.70 0 5 2 ## Lotus Europa 4 95.1 113 3.77 16.90 1 5 2 ## Ford Pantera L 8 351.0 264 4.22 14.50 0 5 4 ## Ferrari Dino 6 145.0 175 3.62 15.50 0 5 6 ## Maserati Bora 8 301.0 335 3.54 14.60 0 5 8 ## Volvo 142E 4 121.0 109 4.11 18.60 1 4 2 6.3 Multiple queries Suggested approach to avoid passing multiple, and similar, queries to the database Create a simple dplyr piped operation that returns the mean of arrdelay for the months of January, February and March as a group. flights %&gt;% filter(month %in% c(1,2,3)) %&gt;% summarise(mean = mean(arrdelay, na.rm = TRUE)) ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## mean ## &lt;dbl&gt; ## 1 11.4 Assign the first operation to a variable called a, and create copy of the operation but changing the selected months to January, March and April. Assign the second one to a variable called b. a &lt;- flights %&gt;% filter(month %in% c(1,2,3)) %&gt;% summarise(mean = mean(arrdelay, na.rm = TRUE)) b &lt;- flights %&gt;% filter(month %in% c(1,3,4)) %&gt;% summarise(mean = mean(arrdelay, na.rm = TRUE)) Use union() to pass a and b at the same time to the database. union(a, b) ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## mean ## &lt;dbl&gt; ## 1 9.41 ## 2 11.4 Assign to a new variable called months an overlapping set of months. months &lt;- list( c(1,2,3), c(1,3,4), c(2,4,6) ) Use map() to cycle through each set of overlapping months. Notice that it returns three separate results, meaning that it went to the database three times. months %&gt;% map( ~ flights %&gt;% filter(month %in% .x) %&gt;% summarise(mean = mean(arrdelay, na.rm = TRUE)) ) ## [[1]] ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## mean ## &lt;dbl&gt; ## 1 11.4 ## ## [[2]] ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## mean ## &lt;dbl&gt; ## 1 9.41 ## ## [[3]] ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## mean ## &lt;dbl&gt; ## 1 11.0 Add a reduce() operation and use union() command to create a single query. months %&gt;% map( ~ flights %&gt;% filter(month %in% .x) %&gt;% summarise(mean = mean(arrdelay, na.rm = TRUE)) ) %&gt;% reduce(function(x, y) union(x, y)) ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## mean ## &lt;dbl&gt; ## 1 9.41 ## 2 11.4 ## 3 11.0 Use show_query() to see the resulting single query sent to the database. months %&gt;% map( ~ flights %&gt;% filter(month %in% .x) %&gt;% summarise(mean = mean(arrdelay, na.rm = TRUE)) ) %&gt;% reduce(function(x, y) union(x, y)) %&gt;% show_query() ## &lt;SQL&gt; ## ((SELECT AVG(&quot;arrdelay&quot;) AS &quot;mean&quot; ## FROM (SELECT * ## FROM (SELECT * ## FROM datawarehouse.vflight) &quot;yyjahnibvd&quot; ## WHERE (&quot;month&quot; IN (1.0, 2.0, 3.0))) &quot;rodprouylm&quot;) ## UNION ## (SELECT AVG(&quot;arrdelay&quot;) AS &quot;mean&quot; ## FROM (SELECT * ## FROM (SELECT * ## FROM datawarehouse.vflight) &quot;wrxoyjobtb&quot; ## WHERE (&quot;month&quot; IN (1.0, 3.0, 4.0))) &quot;xhfbbrqmlx&quot;)) ## UNION ## (SELECT AVG(&quot;arrdelay&quot;) AS &quot;mean&quot; ## FROM (SELECT * ## FROM (SELECT * ## FROM datawarehouse.vflight) &quot;yoownbwbrj&quot; ## WHERE (&quot;month&quot; IN (2.0, 4.0, 6.0))) &quot;capfqsbjon&quot;) 6.4 Multiple queries with an overlaping range Create a table with a from and to ranges. ranges &lt;- tribble( ~ from, ~to, 1, 4, 2, 5, 3, 7 ) See how map2() works by passing the two variables as the x and y arguments, and adding them as the function. map2(ranges$from, ranges$to, ~.x + .y) ## [[1]] ## [1] 5 ## ## [[2]] ## [1] 7 ## ## [[3]] ## [1] 10 Replace x + y with the dplyr operation from the previous exercise. In it, re-write the filter to use x and y as the month ranges map2( ranges$from, ranges$to, ~ flights %&gt;% filter(month &gt;= .x &amp; month &lt;= .y) %&gt;% summarise(mean = mean(arrdelay, na.rm = TRUE)) ) ## [[1]] ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## mean ## &lt;dbl&gt; ## 1 10.3 ## ## [[2]] ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## mean ## &lt;dbl&gt; ## 1 9.19 ## ## [[3]] ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## mean ## &lt;dbl&gt; ## 1 9.45 Add the reduce operation map2( ranges$from, ranges$to, ~ flights %&gt;% filter(month &gt;= .x &amp; month &lt;= .y) %&gt;% summarise(mean = mean(arrdelay, na.rm = TRUE)) ) %&gt;% reduce(function(x, y) union(x, y)) ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## mean ## &lt;dbl&gt; ## 1 9.45 ## 2 9.19 ## 3 10.3 Add a show_query() step to see how the final query was constructed. map2( ranges$from, ranges$to, ~ flights %&gt;% filter(month &gt;= .x &amp; month &lt;= .y) %&gt;% summarise(mean = mean(arrdelay, na.rm = TRUE)) ) %&gt;% reduce(function(x, y) union(x, y)) %&gt;% show_query() ## &lt;SQL&gt; ## ((SELECT AVG(&quot;arrdelay&quot;) AS &quot;mean&quot; ## FROM (SELECT * ## FROM (SELECT * ## FROM datawarehouse.vflight) &quot;attwocpvyv&quot; ## WHERE (&quot;month&quot; &gt;= 1.0 AND &quot;month&quot; &lt;= 4.0)) &quot;dfgzngbeea&quot;) ## UNION ## (SELECT AVG(&quot;arrdelay&quot;) AS &quot;mean&quot; ## FROM (SELECT * ## FROM (SELECT * ## FROM datawarehouse.vflight) &quot;rboeyvlleu&quot; ## WHERE (&quot;month&quot; &gt;= 2.0 AND &quot;month&quot; &lt;= 5.0)) &quot;urkfzzclas&quot;)) ## UNION ## (SELECT AVG(&quot;arrdelay&quot;) AS &quot;mean&quot; ## FROM (SELECT * ## FROM (SELECT * ## FROM datawarehouse.vflight) &quot;ijtvrednjb&quot; ## WHERE (&quot;month&quot; &gt;= 3.0 AND &quot;month&quot; &lt;= 7.0)) &quot;szuobmciyb&quot;) "],
["intro-to-sparklyr.html", "7 Intro to sparklyr 7.1 New Spark session 7.2 Data transfer 7.3 Simple dplyr example 7.4 Map data 7.5 Caching data 7.6 sdf Functions 7.7 Feature transformers 7.8 Fit a model with sparklyr 7.9 Run predictions in Spark", " 7 Intro to sparklyr 7.1 New Spark session Learn to open a new Spark session Use spark_connect() to create a new local Spark session sc &lt;- spark_connect(master = &quot;local&quot;) ## * Using Spark: 2.0.0 Click on the SparkUI button to view the current Spark session’s UI Click on the Log button to see the message history 7.2 Data transfer Practice uploading data to Spark Copy the mtcars dataset into the session spark_mtcars &lt;- sdf_copy_to(sc, mtcars, &quot;my_mtcars&quot;) In the Connections pane, expande the my_mtcars table Go to the Spark UI, note the new jobs In the UI, click the Storage button, note the new table Click on the In-memory table my_mtcars link 7.3 Simple dplyr example See how Spark handles dplyr commands Run the following code snipett spark_mtcars %&gt;% group_by(am) %&gt;% summarise(avg_wt = mean(wt, na.rm = TRUE)) ## # Source: spark&lt;?&gt; [?? x 2] ## am avg_wt ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0 3.77 ## 2 1 2.41 Go to the Spark UI and click the SQL button Click on the top item inside the Completed Queries table At the bottom of the diagram, expand Details 7.4 Map data See the machanics of how Spark is able to use files as a data source Examine the contents of the /usr/share/class/flights/data folder Read the top 5 rows of the flight_2008_1 CSV file. It is located under /usr/share/class/flights library(readr) top_rows &lt;- read_csv(&quot;/usr/share/class/flights/data/flight_2008_1.csv&quot;, n_max = 5) ## Parsed with column specification: ## cols( ## .default = col_double(), ## uniquecarrier = col_character(), ## tailnum = col_character(), ## origin = col_character(), ## dest = col_character(), ## cancellationcode = col_logical(), ## score = col_logical() ## ) ## See spec(...) for full column specifications. Create a list based on the column names, and add a list item with “character” as its value. library(purrr) file_columns &lt;- top_rows %&gt;% rename_all(tolower) %&gt;% map(function(x) &quot;character&quot;) head(file_columns) ## $flightid ## [1] &quot;character&quot; ## ## $year ## [1] &quot;character&quot; ## ## $month ## [1] &quot;character&quot; ## ## $dayofmonth ## [1] &quot;character&quot; ## ## $dayofweek ## [1] &quot;character&quot; ## ## $deptime ## [1] &quot;character&quot; Use spark_read() to “map” the file’s structure and location to the Spark context spark_flights &lt;- spark_read_csv( sc, name = &quot;flights&quot;, path = &quot;/usr/share/class/flights/data/&quot;, memory = FALSE, columns = file_columns, infer_schema = FALSE ) In the Connections pane, click on the table icon by the flights variable Verify that the new variable pointer works by using tally() spark_flights %&gt;% tally() ## # Source: spark&lt;?&gt; [?? x 1] ## n ## &lt;dbl&gt; ## 1 7009728 7.5 Caching data Learn how to cache a subset of the data in Spark Create a subset of the flights table object cached_flights &lt;- spark_flights %&gt;% mutate( arrdelay = ifelse(arrdelay == &quot;NA&quot;, 0, arrdelay), depdelay = ifelse(depdelay == &quot;NA&quot;, 0, depdelay) ) %&gt;% select( month, dayofmonth, arrtime, arrdelay, depdelay, crsarrtime, crsdeptime, distance ) %&gt;% mutate_all(as.numeric) Use compute() to extract the data into Spark memory cached_flights &lt;- compute(cached_flights, &quot;sub_flights&quot;) Confirm new variable pointer works cached_flights %&gt;% tally() ## # Source: spark&lt;?&gt; [?? x 1] ## n ## &lt;dbl&gt; ## 1 7009728 7.6 sdf Functions Overview of a few sdf_ functions: http://spark.rstudio.com/reference/#section-spark-dataframes Use sdf_pivot to create a column for each value in month cached_flights %&gt;% arrange(month) %&gt;% sdf_pivot(month ~ dayofmonth) ## # Source: spark&lt;?&gt; [?? x 32] ## month `1.0` `2.0` `3.0` `4.0` `5.0` `6.0` `7.0` `8.0` `9.0` `10.0` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2 3 4 5 6 7 8 9 10 ## 2 2 1 2 3 4 5 6 7 8 9 10 ## 3 3 1 2 3 4 5 6 7 8 9 10 ## 4 4 1 2 3 4 5 6 7 8 9 10 ## 5 5 1 2 3 4 5 6 7 8 9 10 ## 6 6 1 2 3 4 5 6 7 8 9 10 ## 7 7 1 2 3 4 5 6 7 8 9 10 ## 8 8 1 2 3 4 5 6 7 8 9 10 ## 9 9 1 2 3 4 5 6 7 8 9 10 ## 10 10 1 2 3 4 5 6 7 8 9 10 ## # … with more rows, and 21 more variables: `11.0` &lt;dbl&gt;, `12.0` &lt;dbl&gt;, ## # `13.0` &lt;dbl&gt;, `14.0` &lt;dbl&gt;, `15.0` &lt;dbl&gt;, `16.0` &lt;dbl&gt;, `17.0` &lt;dbl&gt;, ## # `18.0` &lt;dbl&gt;, `19.0` &lt;dbl&gt;, `20.0` &lt;dbl&gt;, `21.0` &lt;dbl&gt;, `22.0` &lt;dbl&gt;, ## # `23.0` &lt;dbl&gt;, `24.0` &lt;dbl&gt;, `25.0` &lt;dbl&gt;, `26.0` &lt;dbl&gt;, `27.0` &lt;dbl&gt;, ## # `28.0` &lt;dbl&gt;, `29.0` &lt;dbl&gt;, `30.0` &lt;dbl&gt;, `31.0` &lt;dbl&gt; Use sdf_partition() to sepparate the data into discrete groups partition &lt;- cached_flights %&gt;% sdf_partition(training = 0.01, testing = 0.09, other = 0.9) tally(partition$training) ## # Source: spark&lt;?&gt; [?? x 1] ## n ## &lt;dbl&gt; ## 1 70102 7.7 Feature transformers See how to use Spark’s feature transformers: http://spark.rstudio.com/reference/#section-spark-feature-transformers Use ft_binarizer() to identify “delayed” flights cached_flights %&gt;% ft_binarizer( input_col = &quot;depdelay&quot;, output_col = &quot;delayed&quot;, threshold = 15 ) %&gt;% select( depdelay, delayed ) %&gt;% head(100) ## # Source: spark&lt;?&gt; [?? x 2] ## depdelay delayed ## &lt;dbl&gt; &lt;dbl&gt; ## 1 -4 0 ## 2 -1 0 ## 3 15 0 ## 4 -2 0 ## 5 2 0 ## 6 -4 0 ## 7 19 1 ## 8 1 0 ## 9 0 0 ## 10 -3 0 ## # … with more rows Use ft_bucketizer() to split the data into groups cached_flights %&gt;% ft_bucketizer( input_col = &quot;crsdeptime&quot;, output_col = &quot;dephour&quot;, splits = c(0, 400, 800, 1200, 1600, 2000, 2400) ) %&gt;% select( crsdeptime, dephour ) %&gt;% head(100) ## # Source: spark&lt;?&gt; [?? x 2] ## crsdeptime dephour ## &lt;dbl&gt; &lt;dbl&gt; ## 1 910 2 ## 2 835 2 ## 3 1555 3 ## 4 730 1 ## 5 2045 5 ## 6 1135 2 ## 7 1310 3 ## 8 1220 3 ## 9 1515 3 ## 10 630 1 ## # … with more rows 7.8 Fit a model with sparklyr Build on the recently learned transformation techniques to feed data into a model Combine the ft_ and sdf_ functions to prepare the da sample_data &lt;- cached_flights %&gt;% filter(!is.na(arrdelay)) %&gt;% ft_binarizer( input_col = &quot;arrdelay&quot;, output_col = &quot;delayed&quot;, threshold = 15 ) %&gt;% ft_bucketizer( input_col = &quot;crsdeptime&quot;, output_col = &quot;dephour&quot;, splits = c(0, 400, 800, 1200, 1600, 2000, 2400) ) %&gt;% mutate(dephour = paste0(&quot;h&quot;, as.integer(dephour))) %&gt;% sdf_partition(training = 0.01, testing = 0.09, other = 0.9) Cache the training data training &lt;- sdf_register(sample_data$training, &quot;training&quot;) tbl_cache(sc, &quot;training&quot;) Run a logistic regression model in Spark delayed_model &lt;- training %&gt;% ml_logistic_regression(delayed ~ depdelay + dephour) View the model results summary(delayed_model) ## Coefficients: ## (Intercept) depdelay dephour_h2 dephour_h3 dephour_h4 dephour_h1 ## -3.5139214 0.1375437 0.9346765 0.7824030 0.8512516 1.0539023 ## dephour_h5 ## 0.7359309 7.9 Run predictions in Spark Quick review of running predictions and reviewing accuracy Use sdf_predict() agains the test dataset delayed_testing &lt;- sdf_predict(delayed_model, sample_data$testing) ## Warning in sdf_predict.ml_model(delayed_model, sample_data$testing): The ## signature sdf_predict(model, dataset) is deprecated and will be removed ## in a future version. Use sdf_predict(dataset, model) or ml_predict(model, ## dataset) instead. delayed_testing %&gt;% head() ## # Source: spark&lt;?&gt; [?? x 17] ## month dayofmonth arrtime arrdelay depdelay crsarrtime crsdeptime distance ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 7 1 NaN 0 -1 1359 1235 282 ## 2 7 1 NaN 0 0 551 527 316 ## 3 7 1 NaN 0 0 850 720 416 ## 4 7 1 NaN 0 0 955 730 1846 ## 5 7 1 NaN 0 0 1019 900 678 ## 6 7 1 NaN 0 0 1116 959 647 ## # … with 9 more variables: delayed &lt;dbl&gt;, dephour &lt;chr&gt;, features &lt;list&gt;, ## # label &lt;dbl&gt;, rawPrediction &lt;list&gt;, probability &lt;list&gt;, ## # prediction &lt;dbl&gt;, probability_0 &lt;dbl&gt;, probability_1 &lt;dbl&gt; Use group_by() to see how effective the new model is delayed_testing %&gt;% group_by(delayed, prediction) %&gt;% tally() %&gt;% mutate(percent = n / sum(n)) ## Warning: Missing values are always removed in SQL. ## Use `sum(x, na.rm = TRUE)` to silence this warning ## Warning: Missing values are always removed in SQL. ## Use `sum(x, na.rm = TRUE)` to silence this warning ## Warning: Missing values are always removed in SQL. ## Use `sum(x, na.rm = TRUE)` to silence this warning ## Warning: Missing values are always removed in SQL. ## Use `sum(x, na.rm = TRUE)` to silence this warning ## # Source: spark&lt;?&gt; [?? x 4] ## # Groups: delayed ## delayed prediction n percent ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 1 10482 0.0211 ## 2 0 0 487204 0.979 ## 3 1 1 91058 0.690 ## 4 1 0 40900 0.310 "],
["spark-pipelines.html", "8 Spark pipelines 8.1 Build a pipeline 8.2 Fit, evaluate, save 8.3 Reload model 8.4 Reload pipeline", " 8 Spark pipelines 8.1 Build a pipeline Step-by-step of how to build a new Spark pipeline Use sdf_partition() to create a sample of 1% training and 1% testing of the flights table. model_data &lt;- sdf_partition( tbl(sc, &quot;flights&quot;), training = 0.01, testing = 0.01, rest = 0.98 ) Recreate the dplyr code in the cached_flights variable from the previous unit. Assign it to a new variable called pepeline_df. pipeline_df &lt;- model_data$training %&gt;% mutate( arrdelay = ifelse(arrdelay == &quot;NA&quot;, 0, arrdelay), depdelay = ifelse(depdelay == &quot;NA&quot;, 0, depdelay) ) %&gt;% select( month, dayofmonth, arrtime, arrdelay, depdelay, crsarrtime, crsdeptime, distance ) %&gt;% mutate_all(as.numeric) Start a new pipeline with ml_pipeline() and dplyr-pipe into ft_dplyr_transformer(). Use pipeline_df as the tbl argument. ml_pipeline(sc) %&gt;% ft_dplyr_transformer( tbl = pipeline_df ) ## Pipeline (Estimator) with 1 stage ## &lt;pipeline_771d46fa3b12&gt; ## Stages ## |--1 SQLTransformer (Transformer) ## | &lt;dplyr_transformer_771d26c841da&gt; ## | (Parameters -- Column Names) Pipe code into ft_binarizer() to determine if arrdelay is over 15 minutes. ml_pipeline(sc) %&gt;% ft_dplyr_transformer( tbl = pipeline_df ) %&gt;% ft_binarizer( input_col = &quot;arrdelay&quot;, output_col = &quot;delayed&quot;, threshold = 15 ) ## Pipeline (Estimator) with 2 stages ## &lt;pipeline_771d790c2547&gt; ## Stages ## |--1 SQLTransformer (Transformer) ## | &lt;dplyr_transformer_771d7c65f40a&gt; ## | (Parameters -- Column Names) ## |--2 Binarizer (Transformer) ## | &lt;binarizer_771d1b32e592&gt; ## | (Parameters -- Column Names) ## | input_col: arrdelay ## | output_col: delayed Pipe code into ft_bucketizer(). Use it to split dephour into six even segments of 4 hours. ml_pipeline(sc) %&gt;% ft_dplyr_transformer( tbl = pipeline_df ) %&gt;% ft_binarizer( input_col = &quot;arrdelay&quot;, output_col = &quot;delayed&quot;, threshold = 15 ) %&gt;% ft_bucketizer( input_col = &quot;crsdeptime&quot;, output_col = &quot;dephour&quot;, splits = c(0, 400, 800, 1200, 1600, 2000, 2400) ) ## Pipeline (Estimator) with 3 stages ## &lt;pipeline_771d55043e5f&gt; ## Stages ## |--1 SQLTransformer (Transformer) ## | &lt;dplyr_transformer_771d397eb5a8&gt; ## | (Parameters -- Column Names) ## |--2 Binarizer (Transformer) ## | &lt;binarizer_771d2ae8baf5&gt; ## | (Parameters -- Column Names) ## | input_col: arrdelay ## | output_col: delayed ## |--3 Bucketizer (Transformer) ## | &lt;bucketizer_771d5bc82de8&gt; ## | (Parameters -- Column Names) ## | input_col: crsdeptime ## | output_col: dephour Add ft_r_formula() with a model that compares uses arrdelay and dephour against depdelay. ml_pipeline(sc) %&gt;% ft_dplyr_transformer( tbl = pipeline_df ) %&gt;% ft_binarizer( input_col = &quot;arrdelay&quot;, output_col = &quot;delayed&quot;, threshold = 15 ) %&gt;% ft_bucketizer( input_col = &quot;crsdeptime&quot;, output_col = &quot;dephour&quot;, splits = c(0, 400, 800, 1200, 1600, 2000, 2400) ) %&gt;% ft_r_formula(delayed ~ arrdelay + dephour) ## Pipeline (Estimator) with 4 stages ## &lt;pipeline_771d461623dc&gt; ## Stages ## |--1 SQLTransformer (Transformer) ## | &lt;dplyr_transformer_771d52515c6e&gt; ## | (Parameters -- Column Names) ## |--2 Binarizer (Transformer) ## | &lt;binarizer_771d6615abc0&gt; ## | (Parameters -- Column Names) ## | input_col: arrdelay ## | output_col: delayed ## |--3 Bucketizer (Transformer) ## | &lt;bucketizer_771de7aa7e3&gt; ## | (Parameters -- Column Names) ## | input_col: crsdeptime ## | output_col: dephour ## |--4 RFormula (Estimator) ## | &lt;r_formula_771d7d7168b8&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | (Parameters) ## | formula: delayed ~ arrdelay + dephour Pipe into a logistic regression model, with ml_logistic_regression() ml_pipeline(sc) %&gt;% ft_dplyr_transformer( tbl = pipeline_df ) %&gt;% ft_binarizer( input_col = &quot;arrdelay&quot;, output_col = &quot;delayed&quot;, threshold = 15 ) %&gt;% ft_bucketizer( input_col = &quot;crsdeptime&quot;, output_col = &quot;dephour&quot;, splits = c(0, 400, 800, 1200, 1600, 2000, 2400) ) %&gt;% ft_r_formula(delayed ~ arrdelay + dephour) %&gt;% ml_logistic_regression() ## Pipeline (Estimator) with 5 stages ## &lt;pipeline_771d59092a6b&gt; ## Stages ## |--1 SQLTransformer (Transformer) ## | &lt;dplyr_transformer_771d68b4188b&gt; ## | (Parameters -- Column Names) ## |--2 Binarizer (Transformer) ## | &lt;binarizer_771d6bdee23c&gt; ## | (Parameters -- Column Names) ## | input_col: arrdelay ## | output_col: delayed ## |--3 Bucketizer (Transformer) ## | &lt;bucketizer_771d547fef7d&gt; ## | (Parameters -- Column Names) ## | input_col: crsdeptime ## | output_col: dephour ## |--4 RFormula (Estimator) ## | &lt;r_formula_771d1ba41a0e&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | (Parameters) ## | formula: delayed ~ arrdelay + dephour ## |--5 LogisticRegression (Estimator) ## | &lt;logistic_regression_771df916e8a&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | prediction_col: prediction ## | probability_col: probability ## | raw_prediction_col: rawPrediction ## | (Parameters) ## | elastic_net_param: 0 ## | fit_intercept: TRUE ## | max_iter: 100 ## | reg_param: 0 ## | standardization: TRUE ## | threshold: 0.5 ## | tol: 1e-06 Assign the entire piped code to a new variable called flights_pipeline flights_pipeline &lt;- ml_pipeline(sc) %&gt;% ft_dplyr_transformer( tbl = pipeline_df ) %&gt;% ft_binarizer( input_col = &quot;arrdelay&quot;, output_col = &quot;delayed&quot;, threshold = 15 ) %&gt;% ft_bucketizer( input_col = &quot;crsdeptime&quot;, output_col = &quot;dephour&quot;, splits = c(0, 400, 800, 1200, 1600, 2000, 2400) ) %&gt;% ft_r_formula(delayed ~ arrdelay + dephour) %&gt;% ml_logistic_regression() flights_pipeline ## Pipeline (Estimator) with 5 stages ## &lt;pipeline_771d78a8fa3c&gt; ## Stages ## |--1 SQLTransformer (Transformer) ## | &lt;dplyr_transformer_771d2ad23958&gt; ## | (Parameters -- Column Names) ## |--2 Binarizer (Transformer) ## | &lt;binarizer_771d51e97378&gt; ## | (Parameters -- Column Names) ## | input_col: arrdelay ## | output_col: delayed ## |--3 Bucketizer (Transformer) ## | &lt;bucketizer_771d2b73307d&gt; ## | (Parameters -- Column Names) ## | input_col: crsdeptime ## | output_col: dephour ## |--4 RFormula (Estimator) ## | &lt;r_formula_771d5d53839c&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | (Parameters) ## | formula: delayed ~ arrdelay + dephour ## |--5 LogisticRegression (Estimator) ## | &lt;logistic_regression_771d7f6d576b&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | prediction_col: prediction ## | probability_col: probability ## | raw_prediction_col: rawPrediction ## | (Parameters) ## | elastic_net_param: 0 ## | fit_intercept: TRUE ## | max_iter: 100 ## | reg_param: 0 ## | standardization: TRUE ## | threshold: 0.5 ## | tol: 1e-06 8.2 Fit, evaluate, save Fit (train) the flights_pipeline pipeline model using the training data on model_data. The function to use is ml_fit() model &lt;- ml_fit( flights_pipeline, model_data$training ) model ## PipelineModel (Transformer) with 5 stages ## &lt;pipeline_771d78a8fa3c&gt; ## Stages ## |--1 SQLTransformer (Transformer) ## | &lt;dplyr_transformer_771d2ad23958&gt; ## | (Parameters -- Column Names) ## |--2 Binarizer (Transformer) ## | &lt;binarizer_771d51e97378&gt; ## | (Parameters -- Column Names) ## | input_col: arrdelay ## | output_col: delayed ## |--3 Bucketizer (Transformer) ## | &lt;bucketizer_771d2b73307d&gt; ## | (Parameters -- Column Names) ## | input_col: crsdeptime ## | output_col: dephour ## |--4 RFormulaModel (Transformer) ## | &lt;r_formula_771d5d53839c&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | (Transformer Info) ## | formula: chr &quot;delayed ~ arrdelay + dephour&quot; ## |--5 LogisticRegressionModel (Transformer) ## | &lt;logistic_regression_771d7f6d576b&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | prediction_col: prediction ## | probability_col: probability ## | raw_prediction_col: rawPrediction ## | (Transformer Info) ## | coefficients: num [1:2] 28.5057 -0.0886 ## | intercept: num -441 ## | num_classes: int 2 ## | num_features: int 2 ## | threshold: num 0.5 Use the newly fitted model to perform predictions using ml_transform(). Use the testing data from model_data predictions &lt;- ml_transform( x = model, dataset = model_data$testing ) Use group_by()/ tally() to see how the model performed predictions %&gt;% group_by(delayed, prediction) %&gt;% tally() ## # Source: spark&lt;?&gt; [?? x 3] ## # Groups: delayed ## delayed prediction n ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 55669 ## 2 1 1 14559 Save the model into disk using ml_save() ml_save(model, &quot;saved_model&quot;, overwrite = TRUE) ## Model successfully saved. list.files(&quot;saved_model&quot;) ## [1] &quot;metadata&quot; &quot;stages&quot; Save the pipeline using ml_save() ml_save(flights_pipeline, &quot;saved_pipeline&quot;, overwrite = TRUE) ## Model successfully saved. list.files(&quot;saved_pipeline&quot;) ## [1] &quot;metadata&quot; &quot;stages&quot; Close the Spark session spark_disconnect(sc) ## NULL 8.3 Reload model Use the saved model inside a different Spark session Open a new Spark connection and reload the data library(sparklyr) sc &lt;- spark_connect(master = &quot;local&quot;, version = &quot;2.0.0&quot;) spark_flights &lt;- spark_read_csv( sc, name = &quot;flights&quot;, path = &quot;/usr/share/class/flights/data/&quot;, memory = FALSE, columns = file_columns, infer_schema = FALSE ) Use ml_load() to reload the model directly into the Spark session reload &lt;- ml_load(sc, &quot;saved_model&quot;) reload ## PipelineModel (Transformer) with 5 stages ## &lt;pipeline_771d78a8fa3c&gt; ## Stages ## |--1 SQLTransformer (Transformer) ## | &lt;dplyr_transformer_771d2ad23958&gt; ## | (Parameters -- Column Names) ## |--2 Binarizer (Transformer) ## | &lt;binarizer_771d51e97378&gt; ## | (Parameters -- Column Names) ## | input_col: arrdelay ## | output_col: delayed ## |--3 Bucketizer (Transformer) ## | &lt;bucketizer_771d2b73307d&gt; ## | (Parameters -- Column Names) ## | input_col: crsdeptime ## | output_col: dephour ## |--4 RFormulaModel (Transformer) ## | &lt;r_formula_771d5d53839c&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## |--5 LogisticRegressionModel (Transformer) ## | &lt;logistic_regression_771d7f6d576b&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | prediction_col: prediction ## | probability_col: probability ## | raw_prediction_col: rawPrediction ## | (Transformer Info) ## | coefficients: num [1:2] 28.5057 -0.0886 ## | intercept: num -441 ## | num_classes: int 2 ## | num_features: int 2 ## | threshold: num 0.5 Create a new table called current. It needs to pull today’s flights. library(lubridate) current &lt;- tbl(sc, &quot;flights&quot;) %&gt;% filter( month == !! month(now()), dayofmonth == !! day(now()) ) show_query(current) ## &lt;SQL&gt; ## SELECT * ## FROM `flights` ## WHERE ((`month` = 1.0) AND (`dayofmonth` = 11)) Run predictions against current using ml__transform(). new_predictions &lt;- ml_transform( x = ml_load(sc, &quot;saved_model&quot;), dataset = current ) Get a quick count of expected delayed flights. The field to check on is called prediction new_predictions %&gt;% summarise(late_fligths = sum(prediction, na.rm = TRUE)) ## # Source: spark&lt;?&gt; [?? x 1] ## late_fligths ## &lt;dbl&gt; ## 1 3979 8.4 Reload pipeline Overview of how to use new data to re-fit the pipeline, thus creating a new pipeline model Use ml_load() to reload the pipeline into the Spark session flights_pipeline &lt;- ml_load(sc, &quot;saved_pipeline&quot;) flights_pipeline ## Pipeline (Estimator) with 5 stages ## &lt;pipeline_771d78a8fa3c&gt; ## Stages ## |--1 SQLTransformer (Transformer) ## | &lt;dplyr_transformer_771d2ad23958&gt; ## | (Parameters -- Column Names) ## |--2 Binarizer (Transformer) ## | &lt;binarizer_771d51e97378&gt; ## | (Parameters -- Column Names) ## | input_col: arrdelay ## | output_col: delayed ## |--3 Bucketizer (Transformer) ## | &lt;bucketizer_771d2b73307d&gt; ## | (Parameters -- Column Names) ## | input_col: crsdeptime ## | output_col: dephour ## |--4 RFormula (Estimator) ## | &lt;r_formula_771d5d53839c&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | (Parameters) ## | formula: delayed ~ arrdelay + dephour ## |--5 LogisticRegression (Estimator) ## | &lt;logistic_regression_771d7f6d576b&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | prediction_col: prediction ## | probability_col: probability ## | raw_prediction_col: rawPrediction ## | (Parameters) ## | elastic_net_param: 0 ## | fit_intercept: TRUE ## | max_iter: 100 ## | reg_param: 0 ## | standardization: TRUE ## | threshold: 0.5 ## | tol: 1e-06 Create a new sample data set using sample_frac(), 1% of the total data should be sufficient sample &lt;- tbl(sc, &quot;flights&quot;) %&gt;% sample_frac(0.001) Re-fit the model using ml_fit() and the new sample data new_model &lt;- ml_fit(flights_pipeline, sample) new_model ## PipelineModel (Transformer) with 5 stages ## &lt;pipeline_771d78a8fa3c&gt; ## Stages ## |--1 SQLTransformer (Transformer) ## | &lt;dplyr_transformer_771d2ad23958&gt; ## | (Parameters -- Column Names) ## |--2 Binarizer (Transformer) ## | &lt;binarizer_771d51e97378&gt; ## | (Parameters -- Column Names) ## | input_col: arrdelay ## | output_col: delayed ## |--3 Bucketizer (Transformer) ## | &lt;bucketizer_771d2b73307d&gt; ## | (Parameters -- Column Names) ## | input_col: crsdeptime ## | output_col: dephour ## |--4 RFormulaModel (Transformer) ## | &lt;r_formula_771d5d53839c&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | (Transformer Info) ## | formula: chr &quot;delayed ~ arrdelay + dephour&quot; ## |--5 LogisticRegressionModel (Transformer) ## | &lt;logistic_regression_771d7f6d576b&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | prediction_col: prediction ## | probability_col: probability ## | raw_prediction_col: rawPrediction ## | (Transformer Info) ## | coefficients: num [1:2] 29.642 -0.447 ## | intercept: num -458 ## | num_classes: int 2 ## | num_features: int 2 ## | threshold: num 0.5 Save the newly fitted model ml_save(new_model, &quot;new_model&quot;, overwrite = TRUE) ## Model successfully saved. list.files(&quot;new_model&quot;) ## [1] &quot;metadata&quot; &quot;stages&quot; Disconnect from Spark spark_disconnect(sc) ## NULL "],
["intro-to-dashboards.html", "9 Intro to dashboards 9.1 Basic structure 9.2 Dropdown data 9.3 Update dashboard items 9.4 Integrate the dropdown 9.5 Add a tabset to the dashboard 9.6 Add interactivity 9.7 Add title to the new tab 9.8 pool pakcage 9.9 Publish dashboard 9.10 Schedule scoring 9.11 Scheduled pipeline 9.12 Scheduled re-fitting", " 9 Intro to dashboards 9.1 Basic structure Preview a simple shinydashboard Create and preview a simple shinydashboard ui &lt;- dashboardPage( dashboardHeader(title = &quot;Quick Example&quot;), dashboardSidebar(selectInput(&quot;select&quot;, &quot;Selection&quot;, c(&quot;one&quot;, &quot;two&quot;))), dashboardBody( valueBoxOutput(&quot;total&quot;), dataTableOutput(&quot;monthly&quot;) ) ) server &lt;- function(input, output, session) { output$total &lt;- renderValueBox(valueBox(100, subtitle = &quot;Flights&quot;)) output$monthly &lt;- renderDataTable(datatable(mtcars)) } shinyApp(ui, server) 9.2 Dropdown data Review a technique to populate a dropdown Use purrr to create a list with the correct structure for the shiny drop down airline_list &lt;- carriers %&gt;% select(carrier, carriername) %&gt;% # In case more fields are added collect() %&gt;% # All would be collected anyway split(.$carriername) %&gt;% # Create a list item for each name map(~.$carrier) # Add the carrier code to each item head(airline_list) ## $`AirTran Airways Corporation` ## [1] &quot;FL&quot; ## ## $`Alaska Airlines Inc.` ## [1] &quot;AS&quot; ## ## $`Aloha Airlines Inc.` ## [1] &quot;AQ&quot; ## ## $`American Airlines Inc.` ## [1] &quot;AA&quot; ## ## $`American Eagle Airlines Inc.` ## [1] &quot;MQ&quot; ## ## $`Atlantic Southeast Airlines` ## [1] &quot;EV&quot; In the app code, replace c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;) with airline_list # Goes from this: dashboardSidebar(selectInput(&quot;select&quot;, &quot;Selection&quot;, c(&quot;one&quot;, &quot;two&quot;))), # To this: dashboardSidebar(selectInput(&quot;select&quot;, &quot;Selection&quot;, airline_list)), Re-run the app 9.3 Update dashboard items Create base query for the dashboard using dplyr and pass the results to the dashboard Save the base “query” to a variable. It will contain a carrier selection. To transition into shiny programming easier, the variable will be a function. base_dashboard &lt;- function(){ flights %&gt;% filter(uniquecarrier == &quot;DL&quot;) } head(base_dashboard()) ## # Source: lazy query [?? x 31] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## flightid year month dayofmonth dayofweek deptime crsdeptime arrtime ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 900594 2008 2 22 5 NA 1555 NA ## 2 900595 2008 2 22 5 NA 755 NA ## 3 900639 2008 2 22 5 NA 930 NA ## 4 899610 2008 2 22 5 753 800 NA ## 5 900640 2008 2 22 5 NA 1030 NA ## 6 900641 2008 2 22 5 NA 1030 NA ## # … with 23 more variables: crsarrtime &lt;dbl&gt;, uniquecarrier &lt;chr&gt;, ## # flightnum &lt;dbl&gt;, tailnum &lt;chr&gt;, actualelapsedtime &lt;dbl&gt;, ## # crselapsedtime &lt;dbl&gt;, airtime &lt;dbl&gt;, arrdelay &lt;dbl&gt;, depdelay &lt;dbl&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, distance &lt;dbl&gt;, taxiin &lt;dbl&gt;, taxiout &lt;dbl&gt;, ## # cancelled &lt;dbl&gt;, cancellationcode &lt;chr&gt;, diverted &lt;dbl&gt;, ## # carrierdelay &lt;dbl&gt;, weatherdelay &lt;dbl&gt;, nasdelay &lt;dbl&gt;, ## # securitydelay &lt;dbl&gt;, lateaircraftdelay &lt;dbl&gt;, score &lt;int&gt; Use the base query to figure the number of flights for that carrier base_dashboard() %&gt;% tally() %&gt;% pull() ## integer64 ## [1] 451931 In the app, remove the 100 number and pipe the dplyr code into the valueBox() function # Goes from this: output$total &lt;- renderValueBox(valueBox(100, subtitle = &quot;Flights&quot;)) # To this: output$total &lt;- renderValueBox( base_dashboard() %&gt;% tally() %&gt;% pull() %&gt;% valueBox(subtitle = &quot;Flights&quot;)) Create a table with the month name and the number of flights for that month base_dashboard() %&gt;% group_by(month) %&gt;% tally() %&gt;% collect() %&gt;% mutate(n = as.numeric(n)) %&gt;% rename(flights = n) %&gt;% arrange(month) ## # A tibble: 12 x 2 ## month flights ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 38256 ## 2 2 36275 ## 3 3 39829 ## 4 4 37049 ## 5 5 36349 ## 6 6 37844 ## 7 7 39335 ## 8 8 38173 ## 9 9 36304 ## 10 10 38645 ## 11 11 36939 ## 12 12 36933 In the app, replace head(mtcars) with the piped code, and re-run the app # Goes from this: output$monthly &lt;- renderTable(head(mtcars)) # To this: output$monthly &lt;- renderDataTable(datatable( base_dashboard() %&gt;% group_by(month) %&gt;% tally() %&gt;% collect() %&gt;% mutate(n = as.numeric(n)) %&gt;% rename(flights = n) %&gt;% arrange(month))) 9.4 Integrate the dropdown Use shiny’s reactive() function to integrate the user input in one spot In the original base_dashboard() code, replace function with reactive, and &quot;DL&quot; with input$select # Goes from this base_dashboard &lt;- function(){ flights %&gt;% filter(uniquecarrier == &quot;DL&quot;)} # To this base_dashboard &lt;- reactive({ flights %&gt;% filter(uniquecarrier == input$select)}) Insert the new code right after the server &lt;- function(input, output, session) line. The full code should now look like this: ui &lt;- dashboardPage( dashboardHeader(title = &quot;Quick Example&quot;), dashboardSidebar(selectInput(&quot;select&quot;, &quot;Selection&quot;, airline_list)), dashboardBody( valueBoxOutput(&quot;total&quot;), dataTableOutput(&quot;monthly&quot;) ) ) server &lt;- function(input, output, session) { base_dashboard &lt;- reactive({ flights %&gt;% filter(uniquecarrier == input$select) }) output$total &lt;- renderValueBox( base_dashboard() %&gt;% tally() %&gt;% pull() %&gt;% valueBox(subtitle = &quot;Flights&quot;) ) output$monthly &lt;- renderDataTable(datatable( base_dashboard() %&gt;% group_by(month) %&gt;% tally() %&gt;% collect() %&gt;% mutate(n = as.numeric(n)) %&gt;% rename(flights = n) %&gt;% arrange(month) )) } shinyApp(ui, server) Re-run the app Disconnect form database dbDisconnect(con) #Dashboard drill-down 9.5 Add a tabset to the dashboard Prepare the ui to accept new tabs based on the user’s input Wrap the “output” functions in the ui with a tabPanel() # Goes from this valueBoxOutput(&quot;total&quot;), dataTableOutput(&quot;monthly&quot;) # To this tabPanel( valueBoxOutput(&quot;total&quot;), dataTableOutput(&quot;monthly&quot;) ) Set the panel’s title and value. The new code should look like this tabPanel( title = &quot;Dashboard&quot;, value = &quot;page1&quot;, valueBoxOutput(&quot;total&quot;), dataTableOutput(&quot;monthly&quot;) ) Wrap that code inside a tabsetPanel(), set the id to tabs tabsetPanel( id = &quot;tabs&quot;, tabPanel( title = &quot;Dashboard&quot;, value = &quot;page1&quot;, valueBoxOutput(&quot;total&quot;), dataTableOutput(&quot;monthly&quot;) ) ) Re-run the app 9.6 Add interactivity Add an click-event that creates a new tab Set the selection and rownames in the current datatable() function output$monthly &lt;- renderDataTable(datatable({ base_dashboard() %&gt;% group_by(month) %&gt;% tally() %&gt;% collect() %&gt;% mutate(n = as.numeric(n)) %&gt;% rename(flights = n) %&gt;% arrange(month)}, list( target = &quot;cell&quot;), # New code rownames = FALSE)) # New code Use observeEvent() and appendTab() to add the interactivity observeEvent(input$monthly_cell_clicked, { appendTab( inputId = &quot;tabs&quot;, # This is the tabsets panel&#39;s ID tabPanel( &quot;test_new&quot;, # This will be the label of the new tab renderDataTable(mtcars, rownames = FALSE) ) ) }) Re-run the app Click on a row inside the datatable and then select the new tab called test_new to see the mtcars data 9.7 Add title to the new tab Use the input’s info to create a custom label Load the clicked cell’s info into a variable, and create a new lable by concatenating the cell’s month and the selected airline’s code observeEvent(input$monthly_cell_clicked, { cell &lt;- input$monthly_cell_clicked # New code if (!is.null(cell$value)) { # New code tab_title &lt;- paste0(month.name[cell$value], &quot;_&quot;, input$select) appendTab( inputId = &quot;tabs&quot;, tabPanel( tab_title, # Changed code renderDataTable(mtcars, rownames = FALSE) ) ) } }) Re-run the app, and click on one of the month’s to confirm that the new label works Use updateTabsetPanel to switch the dashboard’s focus to the newly created tab. It goes after the tabPanel() code updateTabsetPanel(session, &quot;tabs&quot;, selected = tab_title) 9.8 pool pakcage Improve connectivity using the pool package 1.Change dbConnect() to dbPool() # Goes from this con &lt;- DBI::dbConnect(odbc::odbc(), &quot;Postgres Dev&quot;) # To this con &lt;- pool::dbPool(odbc::odbc(), dsn = &quot;Postgres Dev&quot;) Add an onStop() step to close the pool connection onStop(function() { poolClose(con) }) #Share and Production 9.9 Publish dashboard Use RStudio Connect to publish work internally in the enterprise Open the dashboard app.R file Click on File Click on Publish Connect Account click Next Select RStudio Connect Copy and paste your RStudio Server URL and add :3939 Enter your credentials Complete the form Click Proceed Click on Connect Click Publish 9.10 Schedule scoring Use the tidypredict model to score and write back to the database Create a new RMarkdown Start the new RMarkdown by loading all the needed libraries, connecting to the DB and setting table_flights Read the parsed model saved in exercise 5.6 my_pm &lt;- yaml::read_yaml(&quot;my_model.yml&quot;) Copy the code from exercise 5.5 step 4. Load the code into a variable called predictions. Change the model variable to parsedmodel predictions &lt;- table_flights %&gt;% filter(month == 2, dayofmonth == 1) %&gt;% mutate( season = case_when( month &gt;= 3 &amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp; month &lt;= 8 ~ &quot;Summmer&quot;, month &gt;= 9 &amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot; ) ) %&gt;% select( season, depdelay) %&gt;% tidypredict_to_column(parsedmodel) %&gt;% remote_query() Change the select() verb to include flightid, and rename to p_flightid predictions &lt;- table_flights %&gt;% filter(month == 2, dayofmonth == 1) %&gt;% mutate( season = case_when( month &gt;= 3 &amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp; month &lt;= 8 ~ &quot;Summmer&quot;, month &gt;= 9 &amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot; ) ) %&gt;% select(p_flightid = flightid, season, depdelay) %&gt;% tidypredict_to_column(parsedmodel) %&gt;% remote_query() Append to the end, the SQL code needed to run the update inside the database update_statement &lt;- build_sql( &quot;UPDATE datawarehouse.flight SET nasdelay = fit FROM (&quot;, predictions, &quot;) as p &quot;, &quot;WHERE flightid = p_flightid&quot;, con = con ) con &lt;- DBI::dbConnect(odbc::odbc(), &quot;Postgres Dev&quot;) dbSendQuery(con, update_statement) knit the document to confirm it works Click on File and then Publish Select Publish just this document. Confirm that the parsemodel.csv file is included in the list of files that are to be published. In RStudio Connect, select Schedule Click on Schedule output for default Click on Run every weekday (Monday to Friday) Click Save 9.11 Scheduled pipeline See how to automate the pipeline model to run on a daily basis Create a new RMarkdown document Copy the code from the Class catchup section in Spark Pipeline, unit 8 library(tidyverse) library(sparklyr) library(lubridate) top_rows &lt;- read.csv(&quot;/usr/share/class/flights/data/flight_2008_1.csv&quot;, nrows = 5) file_columns &lt;- top_rows %&gt;% rename_all(tolower) %&gt;% map(function(x) &quot;character&quot;) conf &lt;- spark_config() conf$`sparklyr.cores.local` &lt;- 4 conf$`sparklyr.shell.driver-memory` &lt;- &quot;8G&quot; conf$spark.memory.fraction &lt;- 0.9 sc &lt;- spark_connect(master = &quot;local&quot;, config = conf, version = &quot;2.0.0&quot;) spark_flights &lt;- spark_read_csv( sc, name = &quot;flights&quot;, path = &quot;/usr/share/class/flights/data/&quot;, memory = FALSE, columns = file_columns, infer_schema = FALSE ) Move the saved_model folder under /tmp Copy all the code from exercise 8.3 starting with step 2 reload &lt;- ml_load(sc, &quot;saved_model&quot;) reload library(lubridate) current &lt;- tbl(sc, &quot;flights&quot;) %&gt;% filter( month == !! month(now()), dayofmonth == !! day(now()) ) show_query(current) head(current) new_predictions &lt;- ml_transform( x = reload, dataset = current ) new_predictions %&gt;% summarise(late_fligths = sum(prediction, na.rm = TRUE)) Change the ml_load() location to &quot;/tmp/saved_model&quot; Close the Spark session spark_disconnect(sc) knit the document to confirm it works Click on File and then Publish Select Publish just this document Click Publish anyway on the warning In RStudio Connect, select Schedule Click on Schedule output for default Click on Run every weekday (Monday to Friday) Click Save 9.12 Scheduled re-fitting See how to automate the pipeline to re-fit on a monthly basis Create a new RMarkdown document Copy the code from the Class catchup section in Spark Pipeline, unit 8 library(tidyverse) library(sparklyr) library(lubridate) top_rows &lt;- read.csv(&quot;/usr/share/class/flights/data/flight_2008_1.csv&quot;, nrows = 5) file_columns &lt;- top_rows %&gt;% rename_all(tolower) %&gt;% map(function(x) &quot;character&quot;) conf &lt;- spark_config() conf$`sparklyr.cores.local` &lt;- 4 conf$`sparklyr.shell.driver-memory` &lt;- &quot;8G&quot; conf$spark.memory.fraction &lt;- 0.9 sc &lt;- spark_connect(master = &quot;local&quot;, config = conf, version = &quot;2.0.0&quot;) spark_flights &lt;- spark_read_csv( sc, name = &quot;flights&quot;, path = &quot;/usr/share/class/flights/data/&quot;, memory = FALSE, columns = file_columns, infer_schema = FALSE ) Move the saved_pipeline folder under /tmp Copy all the code from exercise 8.4 pipeline &lt;- ml_load(sc, &quot;/tmp/saved_pipeline&quot;) pipeline sample &lt;- tbl(sc, &quot;flights&quot;) %&gt;% sample_frac(0.001) new_model &lt;- ml_fit(pipeline, sample) new_model ml_save(new_model, &quot;new_model&quot;, overwrite = TRUE) list.files(&quot;new_model&quot;) spark_disconnect(sc) Change the ml_load() location to &quot;/tmp/saved_pipeline&quot; knit the document to confirm it works Click on File and then Publish Select Publish just this document Click Publish anyway on the warning In RStudio Connect, select Schedule Click on Schedule output for default On the Schedule Type dropdown, select Monthly Click Save "],
["text-mining-with-sparklyr.html", "10 Text mining with sparklyr 10.1 Data Import 10.2 Tidying data 10.3 Transform the data 10.4 Data Exploration", " 10 Text mining with sparklyr For this example, there are two files that will be analyzed. They are both the full works of Sir Arthur Conan Doyle and Mark Twain. The files were downloaded from the Gutenberg Project site via the gutenbergr package. Intentionally, no data cleanup was done to the files prior to this analysis. See the appendix below to see how the data was downloaded and prepared. readLines(&quot;/usr/share/class/bonus/arthur_doyle.txt&quot;, 30) 10.1 Data Import Open a Spark session library(sparklyr) library(dplyr) conf &lt;- spark_config() conf$`sparklyr.cores.local` &lt;- 4 conf$`sparklyr.shell.driver-memory` &lt;- &quot;8G&quot; conf$spark.memory.fraction &lt;- 0.9 sc &lt;- spark_connect(master = &quot;local&quot;, config = conf,version = &quot;2.0.0&quot;) The spark_read_text() is a new function which works like readLines() but for sparklyr. Use it to read the mark_twain.txt file into Spark. twain_path &lt;- &quot;file:///usr/share/class/bonus/mark_twain.txt&quot; twain &lt;- spark_read_text(sc, &quot;twain&quot;, twain_path) Read the arthur_doyle.txt file into Spark doyle_path &lt;- &quot;file:///usr/share/class/bonus/arthur_doyle.txt&quot; doyle &lt;- spark_read_text(sc, &quot;doyle&quot;, doyle_path) 10.2 Tidying data Add a identification column to each data set. twain_id &lt;- twain %&gt;% mutate(author = &quot;twain&quot;) doyle_id &lt;- doyle %&gt;% mutate(author = &quot;doyle&quot;) Use sdf_bind_rows() to append the two files together both &lt;- doyle_id %&gt;% sdf_bind_rows(twain_id) both Filter out empty lines all_lines &lt;- both %&gt;% filter(nchar(line) &gt; 0) Use Hive’s regexp_replace to remove punctuation all_lines &lt;- all_lines %&gt;% mutate(line = regexp_replace(line, &quot;[_\\&quot;\\&#39;():;,.!?\\\\-]&quot;, &quot; &quot;)) head(all_lines) 10.3 Transform the data Use ft_tokenizer() to separate each word. in the line. It places it in a list column. word_list &lt;- all_lines %&gt;% ft_tokenizer(input_col = &quot;line&quot;, output_col = &quot;word_list&quot;) head(word_list, 4) Remove “stop words” with the ft_stop_words_remover() transformer. The list is of stop words Spark uses is available here: https://github.com/apache/spark/blob/master/mllib/src/main/resources/org/apache/spark/ml/feature/stopwords/english.txt wo_stop &lt;- word_list %&gt;% ft_stop_words_remover(input_col = &quot;word_list&quot;, output_col = &quot;wo_stop_words&quot;) head(wo_stop, 4) Un-nest the tokens inside wo_stop_words using explode(). This will create a row per word. exploded &lt;- wo_stop %&gt;% mutate(word = explode(wo_stop_words)) head(exploded) Select the word and author columns, and remove any word with less than 3 characters. all_words &lt;- exploded %&gt;% select(word, author) %&gt;% filter(nchar(word) &gt; 2) head(all_words, 4) Cache the all_words variable using compute() all_words &lt;- all_words %&gt;% compute(&quot;all_words&quot;) 10.4 Data Exploration Words used the most by author word_count &lt;- all_words %&gt;% group_by(author, word) %&gt;% tally() %&gt;% arrange(desc(n)) word_count Words most used by Twain twain_most &lt;- word_count %&gt;% filter(author == &quot;twain&quot;) twain_most Use wordcloud to visualize the top 50 words used by Twain twain_most %&gt;% head(50) %&gt;% collect() %&gt;% with(wordcloud::wordcloud( word, n, colors = c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;,&quot;#56B4E9&quot;))) Words most used by Doyle doyle_most &lt;- word_count %&gt;% filter(author == &quot;doyle&quot;) doyle_most Used wordcloud to visualize the top 50 words used by Doyle that have more than 5 characters doyle_most %&gt;% filter(nchar(word) &gt; 5) %&gt;% head(50) %&gt;% collect() %&gt;% with(wordcloud::wordcloud( word, n, colors = c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;,&quot;#56B4E9&quot;) )) Use anti_join() to figure out which words are used by Doyle but not Twain. Order the results by number of words. doyle_unique &lt;- doyle_most %&gt;% anti_join(twain_most, by = &quot;word&quot;) %&gt;% arrange(desc(n)) doyle_unique Use wordcloud to visualize top 50 records in the previous step doyle_unique %&gt;% head(50) %&gt;% collect() %&gt;% with(wordcloud::wordcloud( word, n, colors = c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;,&quot;#56B4E9&quot;))) Find out how many times Twain used the word “sherlock” all_words %&gt;% filter(author == &quot;twain&quot;, word == &quot;sherlock&quot;) %&gt;% tally() Against the twain variable, use Hive’s instr and lower to make all ever word lower cap, and then look for “sherlock” in the line twain %&gt;% mutate(line = lower(line)) %&gt;% filter(instr(line, &quot;sherlock&quot;) &gt; 0) %&gt;% pull(line) Most of these lines are in a short story by Mark Twain called A Double Barrelled Detective Story. As per the Wikipedia page about this story, this is a satire by Twain on the mystery novel genre, published in 1902. spark_disconnect(sc) "]
]
